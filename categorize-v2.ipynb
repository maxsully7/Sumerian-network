{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from collections import OrderedDict, Counter\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "DREHEM_IDS = 'clean_drehem_ids.txt'\n",
    "QUEEN_ARCHIVES_IDS = 'queen_archives_pids.txt'\n",
    "QUEEN_OIP_IDS = 'oip_pids.txt'\n",
    "\n",
    "labels = {}\n",
    "labels[\"domesticated_animal\"] = [\"[ox]\", \"[cow]\", \"[sheep]\", \"[goat]\", \"[lamb]\"] # account for plural\n",
    "labels[\"wild_animal\"] = [\"[bear]\", \"[gazelle]\", \"[mountain]\"] # account for \"mountain animal\" and plural\n",
    "labels[\"dead_animal\"] = [\"[die]\"] # find \"die\" before finding domesticated or wild\n",
    "labels[\"leather_object\"] = [\"[boots]\", \"[sandals]\"]\n",
    "labels[\"precious_object\"] = [\"[copper]\", \"[bronze]\", \"[silver]\", \"[gold]\"]\n",
    "labels[\"wool\"] = [\"[wool]\"]\n",
    "labels[\"queens_archive\"] = []\n",
    "\n",
    "class Transaction:\n",
    "    def __init__(self, p_id):\n",
    "        self.p_id = p_id\n",
    "        self.lines = list()\n",
    "        self.lemmas = OrderedDict() # Maps Sumerian text to its lemmatized form\n",
    "        self.label = {} # Maps label to List of defining text\n",
    "        self.sumerian_lemmas = []\n",
    "        \n",
    "    # Create mapping of Sumerian text to its lemmatized form\n",
    "    def get_lemmatization(self):\n",
    "        first_line = 0\n",
    "        for i, s in enumerate(self.lines):\n",
    "            if s.startswith(\"1.\"):\n",
    "                  first_line = i\n",
    "                  break\n",
    "        while first_line < len(self.lines)-1:\n",
    "            if self.lines[first_line] and self.lines[first_line][0].isnumeric() and self.lines[first_line+1].startswith(\"#lem\"):\n",
    "                self.lemmas[self.lines[first_line]] = self.lines[first_line+1]\n",
    "                first_line += 2\n",
    "            else:\n",
    "                first_line += 1\n",
    "                \n",
    "        return self.lemmas\n",
    "    \n",
    "    # Get Sumerian lemmatized text only\n",
    "    def get_sumerian_lemma(self):\n",
    "        #print(item.sumerian_lemmas)\n",
    "        item.sumerian_lemmas = []\n",
    "        for k, v in self.lemmas.items():\n",
    "            #print(v)\n",
    "            result = re.findall(\" .*\\[[a-z]+\\]\", v)\n",
    "            if len(result) == 0:\n",
    "                continue\n",
    "            lemmas = [s[:s.index(\"[\")].strip() for s in result[0].split(\";\") if re.search(\"\\[\", s)]\n",
    "            self.sumerian_lemmas += lemmas\n",
    "        return self.sumerian_lemmas\n",
    "    \n",
    "    # Find the most likely label\n",
    "    def set_label(self):\n",
    "        def find_label(label, line, found) :\n",
    "            for val in labels[label]:\n",
    "                if val in line: \n",
    "                    if label in found.keys():\n",
    "                        found[label].append(line)\n",
    "                    else:\n",
    "                        found[label] = [line]\n",
    "                    return True\n",
    "        found = {}\n",
    "        for line in self.lines:\n",
    "            label = None\n",
    "            # Priority 1: Check for dead animal\n",
    "            if find_label(\"dead_animal\", line, found): continue\n",
    "            # Priority 2: Check for wild animal\n",
    "            if find_label(\"wild_animal\", line, found): continue\n",
    "            # Priority 3: Check for domesticated animal\n",
    "            if find_label(\"domesticated_animal\", line, found): continue\n",
    "            # Priority 4: Check leather, wool, or precious object\n",
    "            if find_label(\"leather_object\", line, found): continue\n",
    "            if find_label(\"precious_object\", line, found): continue\n",
    "            if find_label(\"wool\", line, found): break\n",
    "        # If none match, label as \"Unknown\"\n",
    "        if len(found.keys()) == 0:\n",
    "            found[\"Unknown\"] = [self.lines]\n",
    "        self.label = found\n",
    "        return found\n",
    "            \n",
    "    \n",
    "# Read ORACC files to find transactions with p_ids in `ids`\n",
    "def read_files(subdir, ids, reverse=False):\n",
    "    transactions = list()\n",
    "    for i in range(1, 16):\n",
    "        file_name = \"\"\n",
    "        if i < 10:\n",
    "            file_name += subdir + \"p00\" + str(i) + \".atf\"\n",
    "        else:\n",
    "            file_name += subdir + \"p0\" + str(i) + \".atf\"\n",
    "        \n",
    "        curr_transaction = None\n",
    "        \n",
    "        with open(file_name, encoding=\"utf8\") as file:\n",
    "            print(\"Opening:\", file_name)\n",
    "            for line in file:\n",
    "                line = line.strip()\n",
    "                if line.startswith('&P'):\n",
    "                    p_id = line.split()[0][1:]\n",
    "                    if (not reverse and p_id in ids):\n",
    "                        ids.remove(p_id)\n",
    "                        if curr_transaction:\n",
    "                            transactions.append(curr_transaction)\n",
    "                        transaction = Transaction(p_id)\n",
    "                        curr_transaction = transaction\n",
    "                    elif (reverse and p_id not in ids and len(transactions) <= 200):\n",
    "                        if curr_transaction:\n",
    "                            transactions.append(curr_transaction)\n",
    "                        transaction = Transaction(p_id)\n",
    "                        curr_transaction = transaction\n",
    "                    else:\n",
    "                        if curr_transaction:\n",
    "                            transactions.append(curr_transaction)\n",
    "                        curr_transaction = None\n",
    "                else:\n",
    "                    if curr_transaction:\n",
    "                        curr_transaction.lines.append(line)\n",
    "        \n",
    "        if curr_transaction:\n",
    "            transactions.append(curr_transaction)\n",
    "    \n",
    "    #print(ids)\n",
    "    #assert len(ids) == 0\n",
    "    print(\"Number of transactions:\", len(transactions))\n",
    "    return transactions\n",
    "\n",
    "# Return the IDs of docs to annotate\n",
    "def get_drehem_ids(file):\n",
    "    lst = list()\n",
    "    with open(file, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"P\"):\n",
    "                line = line.strip()\n",
    "                lst.append(line)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening: raw-data/p001.atf\n",
      "Opening: raw-data/p002.atf\n",
      "Opening: raw-data/p003.atf\n",
      "Opening: raw-data/p004.atf\n",
      "Opening: raw-data/p005.atf\n",
      "Opening: raw-data/p006.atf\n",
      "Opening: raw-data/p007.atf\n",
      "Opening: raw-data/p008.atf\n",
      "Opening: raw-data/p009.atf\n",
      "Opening: raw-data/p010.atf\n",
      "Opening: raw-data/p011.atf\n",
      "Opening: raw-data/p012.atf\n",
      "Opening: raw-data/p013.atf\n",
      "Opening: raw-data/p014.atf\n",
      "Opening: raw-data/p015.atf\n",
      "Number of transactions: 429\n",
      "Opening: raw-data/p001.atf\n",
      "Opening: raw-data/p002.atf\n",
      "Opening: raw-data/p003.atf\n",
      "Opening: raw-data/p004.atf\n",
      "Opening: raw-data/p005.atf\n",
      "Opening: raw-data/p006.atf\n",
      "Opening: raw-data/p007.atf\n",
      "Opening: raw-data/p008.atf\n",
      "Opening: raw-data/p009.atf\n",
      "Opening: raw-data/p010.atf\n",
      "Opening: raw-data/p011.atf\n",
      "Opening: raw-data/p012.atf\n",
      "Opening: raw-data/p013.atf\n",
      "Opening: raw-data/p014.atf\n",
      "Opening: raw-data/p015.atf\n",
      "Number of transactions: 275\n",
      "Opening: raw-data/p001.atf\n",
      "Opening: raw-data/p002.atf\n",
      "Opening: raw-data/p003.atf\n",
      "Opening: raw-data/p004.atf\n",
      "Opening: raw-data/p005.atf\n",
      "Opening: raw-data/p006.atf\n",
      "Opening: raw-data/p007.atf\n",
      "Opening: raw-data/p008.atf\n",
      "Opening: raw-data/p009.atf\n",
      "Opening: raw-data/p010.atf\n",
      "Opening: raw-data/p011.atf\n",
      "Opening: raw-data/p012.atf\n",
      "Opening: raw-data/p013.atf\n",
      "Opening: raw-data/p014.atf\n",
      "Opening: raw-data/p015.atf\n",
      "Number of transactions: 120\n"
     ]
    }
   ],
   "source": [
    "list_drehem_ids = get_drehem_ids(DREHEM_IDS)\n",
    "list_queen_ids = get_drehem_ids(QUEEN_ARCHIVES_IDS)\n",
    "list_oip_queen_ids = get_drehem_ids(QUEEN_OIP_IDS)\n",
    "#complete_list = list_drehem_ids + list_queen_ids + list_oip_queen_ids\n",
    "# list_more_data = get_drehem_ids(\"more_training_data.txt\")\n",
    "# more_training_data = read_files(\"raw-data/\", list_more_data)\n",
    "# text = []\n",
    "# with open('more_training_data2.txt', 'w', encoding=\"utf8\") as f:\n",
    "#     for item in more_training_data:\n",
    "#         f.write(item.p_id+\"\\n\")\n",
    "#         item.get_lemmatization()\n",
    "#         for i in item.lemmas.keys():\n",
    "#             f.write(i+\"\\n\")\n",
    "#         f.write(\"\\n\")\n",
    "#all_transactions = read_files(\"raw-data/\", complete_list)\n",
    "non_queen_list = read_files(\"raw-data/\", list_drehem_ids)\n",
    "queen_training_list = read_files(\"raw-data/\", list_queen_ids)\n",
    "queen_test_set = read_files(\"raw-data/\", list_oip_queen_ids)\n",
    "#more_training_data = read_files(\"raw-data/\", complete_list, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "525\n",
      "525\n",
      "299\n",
      "299\n"
     ]
    }
   ],
   "source": [
    "# Populate training and data set\n",
    "\n",
    "for item in queen_training_list:\n",
    "    item.get_lemmatization()\n",
    "    item.set_label()\n",
    "    \n",
    "for item in non_queen_list:\n",
    "    item.get_lemmatization()\n",
    "    item.set_label()\n",
    "    \n",
    "for item in queen_test_set:\n",
    "    item.get_lemmatization()\n",
    "    item.set_label()\n",
    "    \n",
    "            \n",
    "training_data = []\n",
    "training_labels = []\n",
    "test_data = []\n",
    "test_labels = []\n",
    "\n",
    "for item in queen_training_list[:175]:\n",
    "    training_data.append(\" \".join(item.get_sumerian_lemma()))\n",
    "    training_labels.append(\"queen\")\n",
    "    \n",
    "for i in range(len(non_queen_list)):\n",
    "    if i < 350:\n",
    "        training_data.append(\" \".join(non_queen_list[i].get_sumerian_lemma()))\n",
    "        training_labels.append(\"not queen\")\n",
    "    else:\n",
    "        test_data.append(\" \".join(non_queen_list[i].get_sumerian_lemma()))\n",
    "        test_labels.append(\"not queen\")\n",
    "        \n",
    "for item in queen_test_set:\n",
    "    test_data.append(\" \".join(item.get_sumerian_lemma()))\n",
    "    test_labels.append(\"queen\")\n",
    "    \n",
    "for item in queen_training_list[175:]:\n",
    "    test_data.append(\" \".join(item.get_sumerian_lemma()))\n",
    "    test_labels.append(\"queen\")\n",
    "\n",
    "print(len(training_data))\n",
    "print(len(training_labels))\n",
    "print(len(test_data))\n",
    "print(len(test_labels))\n",
    "\n",
    "\n",
    "all_data = training_data + test_data\n",
    "all_labels = training_labels + test_labels\n",
    "\n",
    "queen_data = [x for x, y in zip(all_data, all_labels) if y == \"queen\"]\n",
    "queen_labels = [\"queen\"] * len(queen_data)\n",
    "non_queen_data = [x for x, y in zip(all_data, all_labels) if y == \"not queen\"]\n",
    "non_queen_labels = [\"not queen\"] * len(non_queen_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes Classifer\n",
    "For classifying queen's archives transactions\n",
    "\n",
    "\n",
    "<b>Accuracy</b>: \n",
    "(# true positives + # true negatives) / total #<br><br>\n",
    "<b>Recall</b>:\n",
    "true positives / (true positives + false positives) <br>\n",
    "High recall means that an algorithm returned most of the relevant results <br><br>\n",
    "<b>Precision</b>:\n",
    "true positives / (true positives + false negatives) <br>\n",
    "High precision means that an algorithm returned substantially more relevant results than irrelevant ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'a')\n",
      "(1, 'ab')\n",
      "(2, 'abba')\n",
      "(3, 'abzu')\n",
      "(4, 'adda')\n",
      "(5, 'agaʾus')\n",
      "(6, 'aguziga')\n",
      "(7, 'ak')\n",
      "(8, 'akiti')\n",
      "(9, 'alan')\n",
      "(10, 'am')\n",
      "(11, 'ama')\n",
      "(12, 'amar')\n",
      "(13, 'amarsag')\n",
      "(14, 'an')\n",
      "(15, 'anna')\n",
      "(16, 'anse')\n",
      "(17, 'anubda')\n",
      "(18, 'apinla')\n",
      "(19, 'ara')\n",
      "(20, 'arad')\n",
      "(21, 'arar')\n",
      "(22, 'arua')\n",
      "(23, 'asag')\n",
      "(24, 'asgab')\n",
      "(25, 'asgar')\n",
      "(26, 'aslum')\n",
      "(27, 'atu')\n",
      "(28, 'atua')\n",
      "(29, 'az')\n",
      "(30, 'aŋarak')\n",
      "(31, 'ba')\n",
      "(32, 'babbar')\n",
      "(33, 'bad')\n",
      "(34, 'bala')\n",
      "(35, 'bappir')\n",
      "(36, 'bar')\n",
      "(37, 'barag')\n",
      "(38, 'barakara')\n",
      "(39, 'bisaŋdubak')\n",
      "(40, 'da')\n",
      "(41, 'dab')\n",
      "(42, 'dabin')\n",
      "(43, 'dag')\n",
      "(44, 'dam')\n",
      "(45, 'damgar')\n",
      "(46, 'dara')\n",
      "(47, 'de')\n",
      "(48, 'deg')\n",
      "(49, 'dida')\n",
      "(50, 'didli')\n",
      "(51, 'dikud')\n",
      "(52, 'dim')\n",
      "(53, 'dirig')\n",
      "(54, 'diŋir')\n",
      "(55, 'du')\n",
      "(56, 'dubsar')\n",
      "(57, 'dug')\n",
      "(58, 'duga')\n",
      "(59, 'duh')\n",
      "(60, 'duksium')\n",
      "(61, 'dumu')\n",
      "(62, 'dumumunus')\n",
      "(63, 'dupsik')\n",
      "(64, 'dur')\n",
      "(65, 'durah')\n",
      "(66, 'dusia')\n",
      "(67, 'dusu')\n",
      "(68, 'e')\n",
      "(69, 'eban')\n",
      "(70, 'edula')\n",
      "(71, 'egal')\n",
      "(72, 'egia')\n",
      "(73, 'egir')\n",
      "(74, 'ekisibak')\n",
      "(75, 'eme')\n",
      "(76, 'emuhaldim')\n",
      "(77, 'en')\n",
      "(78, 'engar')\n",
      "(79, 'enna')\n",
      "(80, 'ennuŋ')\n",
      "(81, 'ensik')\n",
      "(82, 'er')\n",
      "(83, 'erin')\n",
      "(84, 'erubatum')\n",
      "(85, 'es')\n",
      "(86, 'esa')\n",
      "(87, 'eses')\n",
      "(88, 'esir')\n",
      "(89, 'ezem')\n",
      "(90, 'eʾud')\n",
      "(91, 'eʾuzga')\n",
      "(92, 'ga')\n",
      "(93, 'gaba')\n",
      "(94, 'gabari')\n",
      "(95, 'gada')\n",
      "(96, 'gag')\n",
      "(97, 'gal')\n",
      "(98, 'gala')\n",
      "(99, 'galamah')\n",
      "(100, 'gardu')\n",
      "(101, 'gaz')\n",
      "(102, 'gaʾar')\n",
      "(103, 'geme')\n",
      "(104, 'gi')\n",
      "(105, 'gid')\n",
      "(106, 'gin')\n",
      "(107, 'gir')\n",
      "(108, 'giranum')\n",
      "(109, 'gizi')\n",
      "(110, 'giŋ')\n",
      "(111, 'gu')\n",
      "(112, 'gub')\n",
      "(113, 'gud')\n",
      "(114, 'gudapin')\n",
      "(115, 'gudeʾusa')\n",
      "(116, 'gugal')\n",
      "(117, 'gukkal')\n",
      "(118, 'gula')\n",
      "(119, 'gunu')\n",
      "(120, 'gur')\n",
      "(121, 'guza')\n",
      "(122, 'guzala')\n",
      "(123, 'hab')\n",
      "(124, 'habuda')\n",
      "(125, 'halub')\n",
      "(126, 'har')\n",
      "(127, 'hi')\n",
      "(128, 'hul')\n",
      "(129, 'hulu')\n",
      "(130, 'hunu')\n",
      "(131, 'hursaŋ')\n",
      "(132, 'hus')\n",
      "(133, 'huŋ')\n",
      "(134, 'ibiza')\n",
      "(135, 'ibtag')\n",
      "(136, 'id')\n",
      "(137, 'idu')\n",
      "(138, 'igi')\n",
      "(139, 'il')\n",
      "(140, 'im')\n",
      "(141, 'imbabbar')\n",
      "(142, 'inim')\n",
      "(143, 'innuri')\n",
      "(144, 'inun')\n",
      "(145, 'iri')\n",
      "(146, 'irsaŋ')\n",
      "(147, 'is')\n",
      "(148, 'itud')\n",
      "(149, 'iŋes')\n",
      "(150, 'ka')\n",
      "(151, 'kag')\n",
      "(152, 'kalag')\n",
      "(153, 'kan')\n",
      "(154, 'kas')\n",
      "(155, 'kasdea')\n",
      "(156, 'kesed')\n",
      "(157, 'ki')\n",
      "(158, 'kib')\n",
      "(159, 'kila')\n",
      "(160, 'kin')\n",
      "(161, 'kingal')\n",
      "(162, 'kinud')\n",
      "(163, 'kir')\n",
      "(164, 'kiri')\n",
      "(165, 'kirimah')\n",
      "(166, 'kisal')\n",
      "(167, 'kisib')\n",
      "(168, 'kisur')\n",
      "(169, 'kiŋ')\n",
      "(170, 'kiŋgia')\n",
      "(171, 'kiŋiri')\n",
      "(172, 'kiʾanaŋ')\n",
      "(173, 'kiʾutu')\n",
      "(174, 'ku')\n",
      "(175, 'kud')\n",
      "(176, 'kug')\n",
      "(177, 'kugbabbar')\n",
      "(178, 'kugsig')\n",
      "(179, 'kuli')\n",
      "(180, 'kunga')\n",
      "(181, 'kunzida')\n",
      "(182, 'kur')\n",
      "(183, 'kurusda')\n",
      "(184, 'kus')\n",
      "(185, 'lahama')\n",
      "(186, 'lal')\n",
      "(187, 'laʾu')\n",
      "(188, 'limmu')\n",
      "(189, 'lu')\n",
      "(190, 'lugal')\n",
      "(191, 'lulim')\n",
      "(192, 'lungak')\n",
      "(193, 'ma')\n",
      "(194, 'mada')\n",
      "(195, 'magur')\n",
      "(196, 'mah')\n",
      "(197, 'malah')\n",
      "(198, 'mana')\n",
      "(199, 'mangaga')\n",
      "(200, 'manu')\n",
      "(201, 'mar')\n",
      "(202, 'mas')\n",
      "(203, 'masab')\n",
      "(204, 'masda')\n",
      "(205, 'masdarea')\n",
      "(206, 'masgal')\n",
      "(207, 'maskim')\n",
      "(208, 'massugidgid')\n",
      "(209, 'min')\n",
      "(210, 'miriza')\n",
      "(211, 'mu')\n",
      "(212, 'mudulum')\n",
      "(213, 'muhaldim')\n",
      "(214, 'munus')\n",
      "(215, 'munusŋesgi')\n",
      "(216, 'musalum')\n",
      "(217, 'musen')\n",
      "(218, 'nabrium')\n",
      "(219, 'nagada')\n",
      "(220, 'nagar')\n",
      "(221, 'namgala')\n",
      "(222, 'namraʾak')\n",
      "(223, 'namsita')\n",
      "(224, 'nar')\n",
      "(225, 'naŋa')\n",
      "(226, 'ne')\n",
      "(227, 'nesaŋ')\n",
      "(228, 'niga')\n",
      "(229, 'nin')\n",
      "(230, 'ninda')\n",
      "(231, 'nita')\n",
      "(232, 'niŋ')\n",
      "(233, 'niŋ2')\n",
      "(234, 'niŋara')\n",
      "(235, 'niŋba')\n",
      "(236, 'niŋdab')\n",
      "(237, 'niŋdirig')\n",
      "(238, 'niŋezemak')\n",
      "(239, 'niŋgu')\n",
      "(240, 'niŋgur')\n",
      "(241, 'niŋin')\n",
      "(242, 'niŋlam')\n",
      "(243, 'nu')\n",
      "(244, 'nua')\n",
      "(245, 'nubanda')\n",
      "(246, 'nud')\n",
      "(247, 'nukirik')\n",
      "(248, 'pad')\n",
      "(249, 'pes')\n",
      "(250, 'piriŋ')\n",
      "(251, 'ragaba')\n",
      "(252, 'rah')\n",
      "(253, 'ri')\n",
      "(254, 'sa')\n",
      "(255, 'sabra')\n",
      "(256, 'sadug')\n",
      "(257, 'sag')\n",
      "(258, 'saggal')\n",
      "(259, 'sagia')\n",
      "(260, 'sagud')\n",
      "(261, 'sah')\n",
      "(262, 'sakkanak')\n",
      "(263, 'sal')\n",
      "(264, 'sanabi')\n",
      "(265, 'sar')\n",
      "(266, 'sarrabdu')\n",
      "(267, 'satam')\n",
      "(268, 'saŋ')\n",
      "(269, 'se')\n",
      "(270, 'selu')\n",
      "(271, 'ses')\n",
      "(272, 'seŋ')\n",
      "(273, 'seŋbar')\n",
      "(274, 'sid')\n",
      "(275, 'sidim')\n",
      "(276, 'sig')\n",
      "(277, 'siki')\n",
      "(278, 'sikiba')\n",
      "(279, 'sila')\n",
      "(280, 'sinig')\n",
      "(281, 'sipad')\n",
      "(282, 'sisa')\n",
      "(283, 'siskur')\n",
      "(284, 'situm')\n",
      "(285, 'su')\n",
      "(286, 'sub')\n",
      "(287, 'sug')\n",
      "(288, 'sugid')\n",
      "(289, 'suhub')\n",
      "(290, 'suhus')\n",
      "(291, 'sukkal')\n",
      "(292, 'sukkalmah')\n",
      "(293, 'sukud')\n",
      "(294, 'sukur')\n",
      "(295, 'sulaʾa')\n",
      "(296, 'sumun')\n",
      "(297, 'sunir')\n",
      "(298, 'suniŋin')\n",
      "(299, 'sunumun')\n",
      "(300, 'susig')\n",
      "(301, 'suʾi')\n",
      "(302, 'tag')\n",
      "(303, 'taskarin')\n",
      "(304, 'teŋ')\n",
      "(305, 'ti')\n",
      "(306, 'tir')\n",
      "(307, 'tu')\n",
      "(308, 'tug')\n",
      "(309, 'tugur')\n",
      "(310, 'tuku')\n",
      "(311, 'tul')\n",
      "(312, 'tum')\n",
      "(313, 'tur')\n",
      "(314, 'tus')\n",
      "(315, 'u')\n",
      "(316, 'ud')\n",
      "(317, 'udtena')\n",
      "(318, 'udu')\n",
      "(319, 'udunita')\n",
      "(320, 'ug')\n",
      "(321, 'ugu')\n",
      "(322, 'ugula')\n",
      "(323, 'ugunu')\n",
      "(324, 'ul')\n",
      "(325, 'um')\n",
      "(326, 'umbin')\n",
      "(327, 'ummud')\n",
      "(328, 'unud')\n",
      "(329, 'ur')\n",
      "(330, 'urgir')\n",
      "(331, 'urtur')\n",
      "(332, 'urud')\n",
      "(333, 'us')\n",
      "(334, 'usakar')\n",
      "(335, 'usbar')\n",
      "(336, 'usim')\n",
      "(337, 'utud')\n",
      "(338, 'utuda')\n",
      "(339, 'uz')\n",
      "(340, 'uzga')\n",
      "(341, 'uzu')\n",
      "(342, 'uzud')\n",
      "(343, 'zabar')\n",
      "(344, 'zabardab')\n",
      "(345, 'zal')\n",
      "(346, 'zid')\n",
      "(347, 'zidgu')\n",
      "(348, 'zidsig')\n",
      "(349, 'zig')\n",
      "(350, 'ziga')\n",
      "(351, 'ziz')\n",
      "(352, 'ziʾa')\n",
      "(353, 'zu')\n",
      "(354, 'zulum')\n",
      "(355, 'zusik')\n",
      "(356, 'ŋal')\n",
      "(357, 'ŋar')\n",
      "(358, 'ŋen')\n",
      "(359, 'ŋes')\n",
      "(360, 'ŋesbun')\n",
      "(361, 'ŋesdu')\n",
      "(362, 'ŋeskiŋti')\n",
      "(363, 'ŋesnud')\n",
      "(364, 'ŋi')\n",
      "(365, 'ŋipar')\n",
      "(366, 'ŋiri')\n",
      "(367, 'ŋurus')\n"
     ]
    }
   ],
   "source": [
    "# Bag of Words model\n",
    "count_vect = CountVectorizer(analyzer = \"word\",\n",
    "                                          tokenizer = None,    \n",
    "                                          preprocessor = None,\n",
    "                                          ngram_range = (1, 1),\n",
    "                                          binary = False,\n",
    "                                          strip_accents='unicode',\n",
    "                                          token_pattern='(?u)\\\\b\\\\w+\\\\b')\n",
    "\n",
    "X_train_counts = count_vect.fit_transform(training_data) # Learn the vocabulary dictionary and return term-document matrix.\n",
    "\n",
    "for x in enumerate(count_vect.get_feature_names()):\n",
    "    print(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['udunita u kir ur itud uzud kir ur udunita mašgal itud akiti sadug u mu e du', 'gud udu u mu.DU kurušda dab itud mu us hulu', 'sila maš sila mu.DU dab itud mu hulu', 'udu maš mu.DU dab itud mu hulu', 'udu niga sadug kag eš udu niga sadug kag ŋipar udu u itud ud zal ziga šag itud mu us hulu']\n",
      "  (0, 55)\t1\n",
      "  (0, 68)\t1\n",
      "  (0, 211)\t1\n",
      "  (0, 256)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 206)\t1\n",
      "  (0, 342)\t1\n",
      "  (0, 148)\t2\n",
      "  (0, 329)\t2\n",
      "  (0, 163)\t2\n",
      "  (0, 315)\t2\n",
      "  (0, 319)\t2\n",
      "  (1, 129)\t1\n",
      "  (1, 333)\t1\n",
      "  (1, 41)\t1\n",
      "  (1, 183)\t1\n",
      "  (1, 318)\t1\n",
      "  (1, 113)\t1\n",
      "  (1, 55)\t1\n",
      "  (1, 211)\t2\n",
      "  (1, 148)\t1\n",
      "  (1, 315)\t1\n",
      "  (2, 202)\t1\n",
      "  (2, 279)\t2\n",
      "  (2, 129)\t1\n",
      "  :\t:\n",
      "  (523, 316)\t1\n",
      "  (523, 228)\t3\n",
      "  (523, 41)\t1\n",
      "  (523, 318)\t1\n",
      "  (523, 211)\t1\n",
      "  (523, 206)\t1\n",
      "  (523, 148)\t1\n",
      "  (523, 315)\t1\n",
      "  (524, 307)\t1\n",
      "  (524, 201)\t1\n",
      "  (524, 100)\t1\n",
      "  (524, 76)\t1\n",
      "  (524, 288)\t1\n",
      "  (524, 189)\t5\n",
      "  (524, 133)\t1\n",
      "  (524, 77)\t1\n",
      "  (524, 291)\t1\n",
      "  (524, 366)\t1\n",
      "  (524, 207)\t1\n",
      "  (524, 157)\t1\n",
      "  (524, 257)\t1\n",
      "  (524, 316)\t1\n",
      "  (524, 318)\t7\n",
      "  (524, 211)\t2\n",
      "  (524, 148)\t1\n"
     ]
    }
   ],
   "source": [
    "print(training_data[0:5])\n",
    "print(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(525, 368)\n",
      "Accuracy:  0.8595317725752508\n",
      "Recall:  0.9004890678941312\n",
      "Precision:  0.824953314659197\n"
     ]
    }
   ],
   "source": [
    "# Get TF-IDF\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "print(X_train_tfidf.shape)\n",
    "# print(X_train_tfidf)\n",
    "\n",
    "# Classifier\n",
    "bag_of_words_classifier = MultinomialNB().fit(X_train_tfidf, training_labels)\n",
    "\n",
    "# Predict\n",
    "X_new_counts = count_vect.transform(test_data)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "predicted = bag_of_words_classifier.predict(X_new_tfidf)\n",
    "\n",
    "# for doc, category in zip(docs_new, predicted):\n",
    "#     print('%r => %s' % (doc, category))\n",
    "# print(predicted)\n",
    "    \n",
    "print(\"Accuracy: \", np.mean(predicted == test_labels))\n",
    "print(\"Recall: \", str(metrics.recall_score(test_labels, predicted, [\"queen\", \"not queen\"], average=\"macro\")))\n",
    "print(\"Precision: \", str(metrics.precision_score(test_labels, predicted, [\"queen\", \"not queen\"], average=\"macro\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(525, 2476)\n",
      "(525, 2476)\n",
      "Accuracy:  0.8996655518394648\n",
      "Recall:  0.9237054085155351\n",
      "Precision:  0.861512027491409\n"
     ]
    }
   ],
   "source": [
    "# Bigram Model\n",
    "bigram_vectorizer = CountVectorizer(analyzer = \"word\",\n",
    "                                    tokenizer = None,\n",
    "                                    preprocessor = None,\n",
    "                                    ngram_range = (2, 2),\n",
    "                                    strip_accents='unicode',\n",
    "                                    token_pattern='(?u)\\\\b\\\\w+\\\\b')\n",
    "\n",
    "# Train\n",
    "X_train_counts = bigram_vectorizer.fit_transform(training_data) # Learn the vocabulary dictionary and return term-document matrix.\n",
    "print(X_train_counts.shape)\n",
    "\n",
    "# Get TF-IDF\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "print(X_train_tfidf.shape)\n",
    "\n",
    "# Classifier\n",
    "bigram_classifier = MultinomialNB().fit(X_train_tfidf, training_labels)\n",
    "\n",
    "# Predict\n",
    "X_new_counts = bigram_vectorizer.transform(test_data)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "bigram_multinomial_nb_prediction = bigram_classifier.predict(X_new_tfidf)\n",
    "\n",
    "print(\"Accuracy: \", np.mean(bigram_multinomial_nb_prediction == test_labels))\n",
    "print(\"Recall: \", str(metrics.recall_score(test_labels, bigram_multinomial_nb_prediction, [\"queen\", \"not queen\"], average=\"macro\")))\n",
    "print(\"Precision: \", str(metrics.precision_score(test_labels, bigram_multinomial_nb_prediction, [\"queen\", \"not queen\"], average=\"macro\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(525, 4711)\n",
      "(525, 4711)\n",
      "Accuracy:  0.8929765886287625\n",
      "Recall:  0.9151035673187572\n",
      "Precision:  0.8541728031418754\n"
     ]
    }
   ],
   "source": [
    "# Trigram Model\n",
    "trigram_vectorizer = CountVectorizer(analyzer = \"word\",\n",
    "                                    tokenizer = None,\n",
    "                                    preprocessor = None,\n",
    "                                    ngram_range = (3, 3),\n",
    "                                    strip_accents='unicode',\n",
    "                                    token_pattern='(?u)\\\\b\\\\w+\\\\b')\n",
    "\n",
    "# Train\n",
    "X_train_counts = trigram_vectorizer.fit_transform(training_data) # Learn the vocabulary dictionary and return term-document matrix.\n",
    "print(X_train_counts.shape)\n",
    "\n",
    "# Get TF-IDF\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "print(X_train_tfidf.shape)\n",
    "\n",
    "# Classifier\n",
    "trigram_classifier = MultinomialNB().fit(X_train_tfidf, training_labels)\n",
    "\n",
    "# Predict\n",
    "X_new_counts = trigram_vectorizer.transform(test_data)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "trigram_prediction = trigram_classifier.predict(X_new_tfidf)\n",
    "\n",
    "print(\"Accuracy: \", np.mean(trigram_prediction == test_labels))\n",
    "print(\"Recall: \", str(metrics.recall_score(test_labels, trigram_prediction, [\"queen\", \"not queen\"], average=\"macro\")))\n",
    "print(\"Precision: \", str(metrics.precision_score(test_labels, trigram_prediction, [\"queen\", \"not queen\"], average=\"macro\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(525, 2844)\n",
      "(525, 2844)\n",
      "Accuracy:  0.9163879598662207\n",
      "Recall:  0.9350690448791714\n",
      "Precision:  0.8799748743718593\n"
     ]
    }
   ],
   "source": [
    "# Unigram and Bigram Model\n",
    "uni_and_bigram_vectorizer = CountVectorizer(analyzer = \"word\",\n",
    "                                            tokenizer = None,\n",
    "                                            preprocessor = None,\n",
    "                                            binary = False,\n",
    "                                            ngram_range = (1,2),\n",
    "                                            strip_accents='unicode',\n",
    "                                            token_pattern='(?u)\\\\b\\\\w+\\\\b')\n",
    "\n",
    "# Train\n",
    "X_train_counts = uni_and_bigram_vectorizer.fit_transform(training_data) # Learn the vocabulary dictionary and return term-document matrix.\n",
    "print(X_train_counts.shape)\n",
    "\n",
    "# Get TF-IDF\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "print(X_train_tfidf.shape)\n",
    "\n",
    "# Classifier\n",
    "uni_and_bigram_classifier = MultinomialNB(0.5).fit(X_train_tfidf, training_labels)\n",
    "\n",
    "# Predict\n",
    "X_new_counts = uni_and_bigram_vectorizer.transform(test_data)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "uni_and_bigram_prediction = uni_and_bigram_classifier.predict(X_new_tfidf)\n",
    "\n",
    "print(\"Accuracy: \", np.mean(uni_and_bigram_prediction == test_labels))\n",
    "print(\"Recall: \", str(metrics.recall_score(test_labels, uni_and_bigram_prediction, [\"queen\", \"not queen\"], average=\"macro\")))\n",
    "print(\"Precision: \", str(metrics.precision_score(test_labels, uni_and_bigram_prediction, [\"queen\", \"not queen\"], average=\"macro\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "GOAL: find more commodity labels in the set of non-queen data\n",
    "\n",
    "DBSCAN Model:\n",
    "Density-Based Spatial Clustering of Applications with Noise. Finds core samples of high density and expands clusters from them. Good for data which contains clusters of similar density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of clusters: 9\n"
     ]
    }
   ],
   "source": [
    "# Build DBSCAN model with Tf-idf vectorizer\n",
    "tfidfvec = TfidfVectorizer(ngram_range=(1,2), min_df = 0.0, max_df = 1.0, decode_error = \"ignore\", token_pattern='(?u)\\\\b\\\\w+\\\\b')\n",
    "\n",
    "# Run DBSCAN\n",
    "trans_list = []\n",
    "trans_dict = {}\n",
    "\n",
    "for trans in non_queen_list:\n",
    "    trans_dict[\" \".join([lemma[2:] for lemma in trans.lemmas])] = trans\n",
    "    trans_list.append(\" \".join([lemma[2:] for lemma in trans.lemmas]))\n",
    "    \n",
    "X1 = tfidfvec.fit_transform(trans_list).toarray()\n",
    "# (1,2),1.0 = 9, (1,2),1.1 = 6, (1,3),1.2 = 7\n",
    "db1 = DBSCAN(eps=1.0, min_samples=len(trans_list)/100).fit(X1)  # Higher eps => More leniency to be same cluster\n",
    "core_samples_mask = np.zeros_like(db1.labels_, dtype=bool)\n",
    "core_samples_mask[db1.core_sample_indices_] = True\n",
    "\n",
    "labels1 = db1.labels_\n",
    "n_clusters_ = len(set(labels1)) - (1 if -1 in labels1 else 0) # Number of clusters in labels\n",
    "print('Estimated number of clusters: %d' % n_clusters_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0\n",
      "========= \n",
      "\n",
      "P100041\n",
      " 6(diš) udu  kišib₃ lu₂-{d}suen  ki ab-ba-kal-la-ta  ba-zi#  {d}šu-{d}suen  lugal kal-ga  lugal uri₅{ki}-ma  lugal an ub-da limmu₂-ba  ur-ku₃-nun-na#  dub-sar#  dumu [...]  ARAD₂-[zu]\n",
      "P101340\n",
      " 2(diš) udu  ki a-ba-{d}en-lil₂-gin₇-ta  ur-ku₃-nun-na  i₃-dab₅  iti ezem-mah  mu e₂ {d}šara₂ ba-du₃  {d}šu-{d}suen  lugal kal-ga  lugal uri₅{ki}-ma  lugal an ub-da limmu₂-ba  ur-ku₃-nun-na  dub-sar  dumu lu₂-{d}nin-gir₂-su [kurušda]  ARAD₂-zu\n",
      "P101341\n",
      " [n] gu₄ [niga]  ki puzur₄-{d}en-lil₂-ta  ur-ku₃-nun-na  i₃-dab₅  iti ezem-mah  mu e₂ {d}šara₂ umma#{ki} ba-du₃  {d}šu-{d}suen  lugal kal-ga  lugal uri₅{ki}-ma  lugal an ub-da limmu₂-ba  ur-ku₃-nun-na  dub-sar  dumu lu₂-{d}nin-gir₂-su kurušda  ARAD₂-zu\n",
      "P101344\n",
      " [x] gu₄  [ki] la-diš-ip-ta  ur-ku₃-nun-na  i₃-dab₅  iti a₂-ki-ti  mu {d}i-bi₂-{d}suen  {d}šu-{d}suen  lugal kal-ga  lugal uri₅{ki}-ma  lugal an ub-da limmu₂-ba  ur-ku₃-nun-na  dub-sar  dumu lu₂-{d}nin-gir₂-su kurušda  ARAD₂-zu\n",
      "P101346\n",
      " 1(diš) sila₄  ki ur-{d}ig-alim-ta  ur-ku₃-nun-na  i₃-dab₅  ša₃ unu{ki}  iti ezem-mah  mu e₂ {d}šara₂ ba-du₃  {d}šu-{d}suen  lugal kal-ga  lugal uri₅{ki}-ma  lugal an ub-da limmu₂-ba  ur-ku₃-nun-na  dub-sar  dumu lu₂-{d}nin-gir₂-[su kurušda]  [ARAD₂-zu]\n",
      "P101401\n",
      " 1(u) 1(diš)#? udu# x-tur  1(diš) udu# ur-nigar{gar}  9(diš) maš₂ kišib₃ didli  o o o 2(u) 1(diš)  ki sa₂-si₂-ta  ba-zi  iti ezem-mah  u₄ 1(diš)-kam  mu e₂ {d}šara₂  {d}šu-{d}suen  lugal kal-ga  lugal uri₅{ki}-ma  lugal an ub-da limmu₂-ba  ur-ku₃#-[nun-na]  dub-sar  dumu lu₂#-[{d}nin-gir₂-su kurušda]  ARAD₂-zu\n",
      "P104243\n",
      " 3(u) 7(diš) udu hi-a  šu-gid₂ su-ga  ki šu-ad-mu-ta  ur-ku₃-nun-na  i₃-dab₅  [iti] ezem-{d}šul-gi  mu e₂ {d}šara₂ ba-du₃  3(u) 7(diš)  {d}šu-{d}suen  lugal kal-ga  lugal uri₅{ki}-ma  lugal an ub-da limmu₂-ba  ur-ku₃-nun-na  dub-sar  dumu lu₂-{d}nin-gir₂-su kurušda  ARAD₂-zu\n",
      "P126137\n",
      " 1(diš) udu  ki {d}nanna-ma-ba-ta  ur-ku₃-nun-na  i₃-dab₅  giri₃ amar-ma-ma  iti ezem-an-na  mu {d}i-bi₂-{d}suen lugal  {d}šu-{d}suen  lugal kal-ga  lugal uri₅{ki}-ma  lugal an ub-da limmu₂-ba  ur-ku₃-nun-na  dub-sar  dumu lu₂-{d}nin-gir₂-su kurušda  ARAD₂-zu\n",
      "P139546\n",
      " 1(u) udu maš₂ hi-a  ki uš-gi-na-ta  ur-ku₃-nun-na [i₃]-dab₅#  [...] x x  iti# ezem-mah  mu e₂ {d}šara₂ ba-du₃  {d}šu-{d}suen  lugal kal-ga  lugal uri₅{ki}-ma  lugal an ub-da limmu₂-ba  ur-ku₃-nun-na  dub-sar  dumu lu₂-{d}nin-abzu  ARAD₂-zu\n",
      "\n",
      "Cluster 1\n",
      "========= \n",
      "\n",
      "P100189\n",
      " 2(diš) udu niga  1(diš) sila₄ ga  ba-uš₂  u₄ 5(diš)-kam  ki lu₂-dingir-ra-ta  ur-nigar{gar}  šu ba-ti  iti šu-eš₅-ša  mu ki-maš{ki} u₃ hu-ur₅-ti{ki} ba-hul\n",
      "P100211\n",
      " 1(diš) udu a? x saga?  1(diš) udu niga  1(diš) maš₂-gal niga  1(diš) udu  2(diš) sila₄ ga  1(diš) kir₁₁ ga  ba-uš₂  u₄ 1(u) 1(diš)-kam  ki lu₂-dingir-ra-ta  ur-nigar{gar}  šu ba-ti  iti še-sag₁₁-ku₅  mu {d}amar-{d}suen lugal\n",
      "P100265\n",
      " 2(diš) udu niga saga us₂  1(diš) gukkal niga  1(diš) u₈ niga  1(diš) udu  1(diš) ud₅  4(diš) sila₄  1(diš) kir₁₁  ba-uš₂ u₄ 1(u) 6(diš)-kam  ki lu₂-dingir-ra-ta  ur-nigar{gar}  šu ba-ti  iti ki-siki-{d}nin-a-zu  mu {d}amar-{d}suen lugal\n",
      "P100335\n",
      " 2(diš) udu  1(diš) sila₄  1(diš) sila₄ ga  ba-uš₂  u₄ 8(diš)-kam  ki na-lu₅-ta  ur-nigar{gar}  šu ba-ti  iti maš-da₃-gu₇  mu us₂-sa ki-maš{ki} ba-hul\n",
      "P100337\n",
      " 2(diš) gu₄ niga  1(diš) amar gu₄  2(diš) udu niga  1(diš) gukkal niga  1(diš) sila₄#?  1(diš) kir₁₁ niga  1(diš) maš₂-gal niga  1(diš) ud₅ niga  1(diš) {munus}aš₂-gar₃  1(diš) udu?  7(diš) maš₂-gal  5(diš) x  1(diš) sila₄ bar-[gal₂]  ba-uš₂ u₄ 2(u) 2(diš)-[kam]  ki lu₂-dingir-ra-ta#  ur-nigar{gar} šu ba-ti#  iti maš-da₃-gu₇ . mu us₂-sa ki-maš{ki} u₃ hu-ur₅-ti{ki} ba-hul\n",
      "P100974\n",
      " 1(diš) gu₄ niga sag-gu₄  1(diš) amar gu₄ ga mar-tu  3(diš) kir₁₁ ga  3(diš) maš₂ ga  ba-uš₂ u₄ 1(u) 7(diš)-kam  ki lu₂-dingir-[ra]  ur-nigar{gar}  šu ba-ti  iti ezem-an-na  mu ki-maš{ki} u₃ hu-ur₅-ti{ki} ba-hul\n",
      "P103475\n",
      " 2(diš) maš₂-gal niga a-dara₄  1(diš) ud₅ a-dara₄  1(diš) sila₄ ga 3(diš) udu hur-sag  1(diš) maš₂ ga a-dara₄  1(diš) {munus}aš₂-gar₃ ga a-dara₄  1(diš) amar maš-da₃  ba-uš₂ u₄ 5(diš)-kam  ki a-hu-ni-ta  ur-nigar{gar}  šu ba-ti  iti ses-da-gu₇  mu us₂-sa ur-bi₂-lum{ki} ba-hul\n",
      "P109526\n",
      " 1(diš) maš₂-gal niga a-dara₄  1(diš) u₈ šimašgi₂  1(diš) maš₂ a-dara₄  1(diš) ud₅ su₄  1(diš) maš-da₃  1(diš) amar az  ba-uš₂ u₄ 3(u)-kam  ki lu₂-dingir-ra-ta#  ur-nigar{gar}  šu ba-ti#  iti ezem-{d}nin-a-zu  mu kur ki-maš{ki} hu-ur₅#-ti{ki} ba-hul\n",
      "P132076\n",
      " 1(diš) maš₂-gal a [dara₄]  1(diš) kir₁₁ a-udu hur-sag  1(diš) maš-da₃  1(diš) amar ga  ba-uš₂ u₄ 1(u) 6(diš)-kam  ki lu₂-dingir-ra  ur-nigar{gar}  šu ba-ti  iti u₅-bi₂-gu₇  mu ki-maš{ki} u₃ hu-ur₅-ti{ki} ba-hul\n",
      "P303570\n",
      " 1(diš) sila₄ 1(diš) kir₁₁  1(diš) kir₁₁ gukkal  ba-uš₂  u₄ 2(u) 5(diš)-kam  ki na-lu₅-ta  ur-nigar{gar}  šu ba-ti  iti še-sag₁₁-ku₅  mu {d}amar-{d}suen lugal\n",
      "P303801\n",
      " 1(diš) udu niga saga us₂  ba-uš₂  u₄ 2(u) 7(diš)-kam  ki na-lu₅-ta  ur-nigar{gar}  šu ba-ti  iti ezem-{d}šul-gi  mu us₂-sa ki-maš{ki} u₃ hu-ur₅-ti{ki} ba-hul\n",
      "P429788\n",
      " 1(diš) gu₄ 2(u) udu 5(u) 2(diš) maš₂  in-da-da nu-banda₃  ugula ur-{d}suen  2(diš) gu₄ niga 4(u) la₂ 1(diš) udu  2(u) maš₂-gal 1(diš) sila₄  ar-ši-ah nu-banda₃  2(diš) gu₄ 2(u) udu  erin₂ maš-kan₂-u₂-šu-re₂{ki}  ugula lugal-pa-e₃ . 1(diš) gu₄ niga 5(diš) udu . 4(diš) maš₂-gal 1(diš) maš₂ . lu₂-kal-la nu-banda₃ . 1(diš) gu₄ niga 4(diš) udu . 5(diš) maš₂-gal 1(diš) maš₂ . lu₂-ša-lim nu-banda₃  1(diš) gu₄ niga 4(diš) udu  5(diš) maš₂-gal 1(diš) maš₂  ṣi-ra-am nu-banda₃  ugula sag-{d}nanna-zu  5(diš) udu niga 1(diš) sila₄ za-ri-iq  1(diš) sila₄ ku₅-ra₂-mu  4(diš) udu niga 2(diš) sila₄ ensi₂ nibru{ki}  4(diš) udu niga 1(diš) sila₄ gi-nu-na nu-banda₃  1(diš) sila₄ id-da-a . 1(diš) sila₄ lugal-a₂-zi-da sukkal . 2(diš) sila₄ zabar-dab₅ . 4(diš) maš₂-[gal] su₄ niga 1(diš) {munus}aš₂-gar₃ niga . ur-nigar{gar} ka-guru₇ . 1(diš) sila₄ zi₂-na-na . 1(diš) {munus}aš₂-gar₃ nu-ur₂-i₃-li₂ nu-banda₃ . 1(diš) maš-da₃ bu-bu . 1(diš) udu niga šimašgi 1(diš) maš₂-gal niga šimašgi . 1(diš) {munus}aš₂-gar₃ niga e₂-a-i₃-li₂ . mu-kuₓ(DU) na-sa₆ i₃-dab₅  iti šu-eš₅-ša  mu ha-ar-ši{ki} ki-maš{ki} hu-ur#-ti{ki} u₃ ma-da#-bi u₄ 1(aš)-a ba-hul  u₄ 2(u) 6(diš)-kam\n",
      "\n",
      "Cluster 2\n",
      "========= \n",
      "\n",
      "P100228\n",
      " 1(diš) sila₄ {d}en-lil₂  1(diš) sila₄ {d}nin-lil₂  mu-kuₓ(DU) šeš-da-da sanga  1(diš) sila₄ {d}en-lil₂  1(diš) sila₄ {d}nin-lil₂  mu-kuₓ(DU) en {d}inanna  1(diš) sila₄ {d}utu  mu-kuₓ(DU) ur-du₆  zabar-dab₅ maškim  1(diš) gu₄ niga 3(diš) u₈ ba-uš₂  e₂-muhaldim-še₃  u₄ 1(u) 1(diš)-kam  zi-ga  iti ezem-{d}nin-a-zu  mu en {d}nanna maš-e i₃-pa₃\n",
      "P100321\n",
      " 1(diš) sila₄ {d}en-lil₂  1(diš) sila₄ {d}nin-lil₂  mu-kuₓ(DU) en {d}inanna  1(diš) sila₄ {d}en-lil₂ . 1(diš) maš₂?-nita₂ . 5(diš) udu-nita₂ . zu!-ri-im . lu₂ kin-gi₄-a lu₂ eb-la{ki} . mu ki-maš{ki} u₃ hu-ur₅-ti{ki} ba-hul\n",
      "P100327\n",
      " 2(diš) udu 2(diš) maš₂ 1(diš) sila₄ {d}en-lil₂  2(diš) udu 2(diš) maš₂ 1(diš) sila₄ {d}nin-lil₂  1(diš) sila₄ {d}nanna  1(diš) sila₄ {d}nusku  1(diš) sila₄ {d}nin-urta  ša₃ e₂ {d}nin-lil₂-la₂  1(diš) sila₄ {d}nin-ti₂-ug₅-ga  1(diš) sila₄ {d}nin-hur-sag  1(diš) sila₄ {d}en-ki . 1(diš) sila₄# {d}šul-gi . [a₂ ge₆]-ba-a . 2(diš) sila₄ du₆-[ku₃] . en-{d}nanše-ki-ag₂ maškim . u₄ 2(u) 8(diš)-[kam] . šu+nigin 1(diš) ab₂ mu [x] 1(u) 3(diš) udu . šu+nigin 3(u) la₂ 1(diš) udu# 1(u) 1(diš) maš₂ . bala a-hu-ma ensi₂ nibru{ki} . ki ab-ba-sa₆-ga-ta ba-zi . iti šu-eš-ša . mu {d}amar-{d}suen lugal  5(u) 4(diš)\n",
      "P101389\n",
      " 1(diš) sila₄ {d}en-lil₂  1(diš) sila₄ {d}nin-lil₂  2(diš) udu niga  mu-kuₓ(DU)-ta x zu [...]  4(diš) udu niga 1(diš) udu [...]  1(diš) sila₄? [...] en [...]  e₂-uz-[ga]  1(diš) sila₄ {d}[en-lil₂]  1(diš) sila₄ {d}nin-lil₂ . mu-kuₓ(DU) šeš da-da#-[ga] . 1(diš) sila₄ {d}[...] . mu-kuₓ(DU) dingir-su-[ra-bi₂] . ARAD₂-mu [...]  2(diš) maš-da₃ [...]  mu-kuₓ(DU) e₂-a-i₃#-[li₂]  1(u) la₂ 1(diš) udu 4(diš) [...]  1(diš) u₈ 4(diš) [...]  3(diš) [...]  šu-gid₂ e₂-muhaldim-[še₃]  u₄ 1(u) 1(diš)-kam  ki na-sa₆-ta ba-zi  iti a₂-ki-ti . mu us₂-sa ki-maš{ki} ba-hul mu us₂-sa-bi\n",
      "P101390\n",
      " 1(diš) udu niga {d}en-lil₂  mu-kuₓ(DU) a-hi-e₂-a  1(diš) sila₄ {d}nin-lil₂  mu-kuₓ(DU) ta-la-a-a  1(diš) gukkal niga {d}en-lil₂  1(diš) gukkal niga {d}nin-lil₂  mu-kuₓ(DU) ur-{d}en-lil₂  1(diš) sila₄ {d}en-lil₂  mu-kuₓ(DU) zabar-dab₅ . 1(diš) sila₄ {d}nin-lil₂ . mu-kuₓ(DU) ur-{d}suen  {d}nanše-GIR₂@g?-gal maškim  1(diš) sila₄ mu-kuₓ(DU) ARAD₂-mu  1(diš) maš₂ mu-kuₓ(DU) ṣe-lu-uš-{d}da-gan  e₂-uz-ga  ur-{d}ba-[ba₆ maškim]  2(diš) udu a-wa-at-i₃-li₂ x  ARAD₂-mu maškim  1(diš) gu₄ 3(diš) udu 4(diš) u₈ 3(diš) [...]  3(diš) maš₂ 2(diš) ud₅ šu-gid₂ e₂-muhaldim-še₃ . u₄ 3(u) la₂ 1(diš)-kam . ki na-sa₆-ta ba-zi . iti ezem-mah . mu ha-ar-ši{ki} u₃ ki-maš{ki} ba-hul\n",
      "P123339\n",
      " 1(diš) sila₄ {d}en-lil₂  mu-kuₓ(DU) lu₂-du₁₀-ga šuš₃  1(diš) sila₄ {d}nin-lil₂  mu-kuₓ(DU) na-silim  1(diš) sila₄ {d}na-na-a  mu-kuₓ(DU) ta₂-ki-il-{d}en-lil₂  1(diš) sila₄ an-nu-ni-tum  mu-kuₓ(DU) lu₂-{d}nin-šubur  zabar-dab₅ maškim  u₄ 3(diš)-kam  zi-ga iti ezem-mah  mu en {d}nanna maš-e i₃-pa₃\n",
      "\n",
      "Cluster 3\n",
      "========= \n",
      "\n",
      "P100263\n",
      " 6(diš) sila₄ ga  2(diš) kir₁₁ ga  3(diš) maš₂ ga  2(diš) {munus}aš₂-gar₃ ga  u₃-tu-da  u₄ 1(u) 2(diš)-kam  ki a-hu-ni  iti ki-siki-{d}nin-a-zu  mu {d}amar-{d}suen lugal\n",
      "P100266\n",
      " 2(u) sila₄ ga  8(diš) kir₁₁ ga  4(diš) maš₂ ga  3(diš) {munus}aš₂-gar₃ ga  u₃-tu-da  u₄ 8(diš)-kam  ša₃ na-gab₂-tum  lu₂-dingir-ra i₃-dab₅  iti ezem-me-ki-gal₂  mu {d}amar-{d}suen lugal  3(u) 5(diš)\n",
      "P101315\n",
      " 7(diš) sila₄ ga  6(diš) kir₁₁ ga  5(diš) maš₂ ga  5(diš) {munus}aš₂-gar₃ ga  u₃-tu-da  u₄ 3(u) la₂ 1(diš)-kam  a-hu-ni i₃-dab₅  iti ezem-an-na  mu {d}amar-{d}suen lugal  2(u) 3(diš)\n",
      "P101324\n",
      " 2(diš) sila₄ ga  2(diš) kir₁₁ ga  u₃-tu-da  ša₃ na-gab₂-tum  u₄ 1(u) 2(diš)-kam  {d}šul-gi-a-a-mu i₃-dab₅  iti ki-siki-{d}nin-a-zu  mu {d}gu-za {d}en-lil₂-la₂ ba-dim₂  4(diš)\n",
      "P107663\n",
      " 3(diš) sila₄ ga  6(diš) kir₁₁ ga  2(diš) {munus}aš₂-gar₃ ga  ša₃ uri₅{ki}-ma  4(diš) sila₄ ga  6(diš) kir₁₁ ga  5(diš) maš₂ ga  9(diš) {munus}aš₂-gar₃ ga  ša₃ nibru{ki}  šu+nigin 7(diš) sila₄ ga  šu+nigin 1(u) 2(diš) kir₁₁ ga  šu+nigin 5(diš) maš₂ ga  šu+nigin 1(u) 1(diš) {munus}aš₂-gar₃ ga  u₃-tu-da  ki na-lu₅  iti še-sag₁₁-ku₅ . mu ki-maš{ki} u₃ hu-ur₅-ti{ki} ba-hul\n",
      "\n",
      "Cluster 4\n",
      "========= \n",
      "\n",
      "P100297\n",
      " 3(diš) gu₄ 2(diš) ab₂ e₂-muhaldim  u₄ 1(diš)-kam  1(diš) gu₄ 3(diš) ab₂  u₄ 2(diš)-kam  2(diš) gu₄ 4(diš) ab₂  u₄ 3(diš)-kam  4(diš) gu₄ 1(diš) ab₂  u₄ 4(diš)-kam  4(diš) gu₄ 2(diš) ab₂ . u₄ 5(diš)-kam . 1(diš) gu₄ u₄ 6(diš)-kam . 1(diš) gu₄ 3(diš) ab₂ . u₄ 7(diš)-kam . 3(diš) ab₂ u₄ 8(diš)-kam . 3(diš) gu₄ 1(diš) ab₂ . u₄ 1(u) la₂ 1(diš)-kam . 2(diš) gu₄ 4(diš) ab₂ u₄ 1(u)-kam . 1(diš) gu₄ 2(diš) ab₂ u₄ 1(u) 1(diš)-kam  2(diš) gu₄ u₄ 1(u) 2(diš)-kam  2(u) 2(diš) gu₄ 4(diš) ab₂  u₄ 1(u) 3(diš)-kam  1(diš) gu₄ u₄ 1(u) 7(diš)-kam  4(diš) gu₄ 2(diš) ab₂  u₄ 1(u) 8(diš)-kam  1(diš) gu₄ 2(diš) ab₂ u₄ 2(u) 1(diš)-kam  2(diš) gu₄ 2(diš) ab₂ u₄ 2(u) 2(diš)-kam  4(diš) gu₄ 1(diš) ab₂ u₄ 2(u) 3(diš)-kam . 1(diš) gu₄ u₄ 2(u) 4(diš)-kam . e₂-muhaldim-še₃ . šu+nigin 5(u) 8(diš) gu₄ . šu+nigin 3(u) 6(diš) ab₂ . ki {d}en-lil₂-la₂-ta ba-zi . iti a₂-ki-ti . mu {d}amar-{d}suen lugal-e ur-bi₂-lum{ki} mu-hul  1(geš₂) 3(u) 4(diš) gu₄ ab₂ hi-<a>\n",
      "P101327\n",
      " 1(diš) gu₄ u₄ 8(diš)-kam  5(diš) gu₄ 3(diš) ab₂  u₄ 1(u) 2(diš)-kam  1(u) 4(diš) gu₄ mu 3(diš)  1(diš) ab₂ 3(diš) ab₂ mu 3(diš)  1(diš) {anše}kunga₂-nita₂  4(diš) {anše}kunga₂ munus  [u₄] 1(u) 3(diš)-kam  [2(diš)] {anše}kunga₂-nita₂ . [u₄] 2(u)-kam . 1(diš) gu₄ u₄ 2(u) 6(diš)-kam . šu+nigin 8(diš) gu₄ . šu+nigin 1(u) 4(diš) gu₄ mu 3(diš) . šu+nigin 4(diš) ab₂ . šu+nigin 3(diš) ab₂ mu 3(diš) . šu+nigin 3(diš) {anše}kunga₂-nita₂ . šu+nigin 4(diš) {anše}kunga₂ munus . mu-kuₓ(DU) ki du₁₁-ga-ta . {d}en-lil₂-la₂ i₃-dab₅ . iti ezem-mah . mu ma₂-dara₃-abzu {d}en-ki-ka ba-ab-du₈  3(u) la₂ 1(diš) gu₄ 7(diš) anše\n",
      "P101336\n",
      " 5(u) 1(diš) udu niga  4(u) 3(diš) udu niga gu₄-e-us₂-sa  u₄ 1(diš)-kam  1(diš) udu niga 4(diš)-kam us₂  u₄ 2(diš)-kam  2(diš) gu₄ u₂  4(diš) gu₄ mu 3(diš)  1(u) 3(diš) gu₄ mu 2(diš)  1(diš) ab₂ u₂ . 2(diš) ab₂ mu 2(diš) . 1(diš) udu a-lum niga 3(diš)-kam us₂ . 2(diš) udu niga . 5(diš) gukkal niga . 5(diš) udu a-lum niga . 2(diš) gukkal u₂ . 1(u) 6(diš) sila₄ u₂ . 2(u) 3(diš) udu a-lum u₂ . 2(diš) gukkal u₂ . 1(u) 4(diš) gukkal geš-du₃ u₂ . u₄ 3(diš)-kam . 1(u) sila₄ . u₄ 4(diš)-kam . 1(u) sila₄ . u₄ 5(diš)-kam . 1(diš) gu₄ niga 3(diš)-kam us₂ . 3(diš) udu niga . 1(u) sila₄  u₄ [6(diš)-kam]  2(diš) udu [...]  u₄ [7(diš)-kam]  5(diš) udu [...]  2(u) 2(diš) maš₂ [...]  5(u) 2(diš) ud₅  u₄ 1(u)-kam  1(diš) udu a-lum u₂  u₄ 1(u) 1(diš)-kam . 6(diš) gu₄ [...] . 2(geš₂) 4(u) 1(diš) udu [...] . 6(diš) maš₂-gal . u₄ 1(u) 4(diš)-kam . 1(diš) udu niga 3(diš)-kam us₂ . u₄ 1(u) 9(diš)-kam . 2(diš) udu a-lum niga . 1(u) 2(diš) udu u₂ . 1(geš₂) maš₂-gal u₂ . u₄ 2(u) 3(diš)-kam . 1(u) 7(diš) gukkal u₂ . 2(diš) gukkal geš-du₃ u₂ . 1(u) 9(diš) udu gukkal u₂ . u₄ 2(u) 5(diš)-kam . 1(diš) am gu₄ . 2(diš) gu₄ u₂ . 1(geš₂) 4(u) 3(diš) udu u₂  3(diš) maš₂-gal  u₄ 2(u) 6(diš)-[kam]  šu+nigin 1(diš) gu₄ niga 3(diš)-kam us₂  šu+nigin 1(u) 5(diš) gu₄ u₂  šu+nigin 1(diš) ab₂ u₂  šu+nigin 4(diš) gu₄ mu 3(diš)  šu+nigin 1(u) 3(diš) gu₄ mu 2(diš)  šu+nigin 2(diš) ab₂ mu 2(diš)  šu+nigin 1(diš) am gu₄ . šu+nigin 1(diš) udu niga 3(diš)-kam us₂ . šu+nigin 1(diš) udu a-lum niga 3(diš)-kam us₂ . šu+nigin 1(diš) udu niga 4(diš)-kam us₂ . šu+nigin 5(u) 3(diš) udu [...] . šu+nigin 5(diš) gukkal [...] . šu+nigin 7(diš) udu [...] . šu+nigin 4(u) 1(diš) [...] . šu+nigin 2(diš) [...] . šu+nigin 1(diš) [...]  šu+nigin 3(u) 4(diš) gukkal u₂  šu+nigin 1(u) 6(diš) gukkal geš-du₃ u₂  šu+nigin 2(u) 4(diš) udu a-lum u₂  šu+nigin 2(u) 1(diš) udu gukkal u₂  šu+nigin 3(u) 2(diš) maš₂-gal u₂  šu+nigin 5(u) 2(diš) ud₅ u₂  šu+nigin 3(diš) sila₄  3(u) 6(diš) gu₄  1(diš) am . 8(geš₂) 3(u) 6(diš) udu . ki in-ta-e₃-a-ta . du-u₂-du . i₃-dab₅ . iti ki-siki-{d}nin-a-zu . mu {d}šu-{d}suen lugal uri₅{ki}-ma-ke₄ na-ru₂-a-mah {d}en-lil₂ {d}nin-lil₂-ra mu-ne-du₃\n",
      "P101395\n",
      " 1(diš) udu [...]  1(diš) [...]  u₄ 1(diš)-kam  2(diš) udu [...]  3(diš) gukkal niga  4(diš) udu a-lum niga  1(diš) maš₂-gal niga  1(diš) udu u₂  1(diš) maš₂-gal u₂ . u₄ 7(diš)-kam . 1(diš) udu a-lum niga 4(diš)-kam us₂ . u₄ 8(diš)-[kam] . 1(diš) gukkal [x] . 2(diš) udu a-lum u₂ . 1(diš) maš₂-gal [...] . 4(diš) udu u₂ . 1(diš) udu a-lum niga . 3(diš) maš₂-gal u₂ . u₄ 9(diš)-[kam] . 1(diš) udu niga . 4(diš) udu [x]  u₄ [x-kam]  1(diš) udu [...]  u₄ [x-kam]  4(diš) [...]  1(diš) [...]  1(diš) [...]  u₄ [x-kam]  šu+nigin [...] a. šu+nigin [...] b. šu+nigin 8(diš) [...] š. šu+nigin 4(diš) [...] d. šu+nigin 7(diš) [...] e. šu+nigin 2(diš) maš₂ [...] f. šu+nigin 1(u) [...] g. šu+nigin 1(diš) udu a-lum [...] h. šu+nigin 1(u) 1(diš) [...] i. šu+nigin 1(diš) [...] . ki in-[ta-e₃-a-ta] . nu x [...] . iti ezem-[...] . mu {d}šu-{d}suen [bad₃] ma-da [mu-du₃]\n",
      "P101403\n",
      " 2(u) udu u₂ alan didli  ša₃ e₂ {d}en-lil₂-la₂  1(u) 7(diš) udu u₂ alan didli  ša₃ e₂ {d}nin-lil₂-la₂  uzu-a bala  siskur₂ gu-la  lugal kuₓ(KWU636)-ra  1(diš) ab₂ u₂  2(u) udu u₂ . 1(u) 7(diš) u₈ u₂ . 1(u) 8(diš) maš₂-gal u₂ . šu-gid₂ e₂-muhaldim . lugal uri₅{ki}-še₃ du-ni ma₂-a ba-a-gar . ARAD₂-mu maškim . ša₃ nibru{ki} . 1(diš) gu₄ 1(geš₂) 3(u) 2(diš) udu . u₄ 1(diš)-kam . 1(u) udu u₂ alan didli . ša₃ e₂ {d}inanna . uzu-a bala . siskur₂ gu-la . lugal kuₓ(KWU636)-ra . 2(u) [udu u₂ alan didli] . ša₃ e₂ {d}en-lil₂-la₂ . 2(u) udu u₂ alan didli  ša₃ e₂ {d}nin-lil₂  uzu-a bala  siskur₂ gu-la  puzur₄-eš₁₈?-dar? sagi maškim  ša₃ nibru{ki}  4(u) udu  u₄ 6(diš)-kam  2(u) 4(diš) udu u₂ . 1(u) 1(diš) u₈ u₂ . 2(u) maš₂-gal u₂ . mu AŠ PAP i-bu-hu . ša₃ um ma du [...]-še₃? . lugal-ma₂-gur₈-re maškim . ša₃ uri₅{ki}-ma . 1(diš) gu₄ 5(u) 5(diš) udu . u₄ 1(u) 1(diš)-kam . 2(u) udu u₂ alan didli . ša₃ e₂ {d}en-lil₂-la₂ . 2(u) udu u₂ alan didli . ša₃ e₂ {d}nin-lil₂-la₂ . uzu-a bala . siskur₂ gu-la . {d}šu-{d}suen-ma-ha-ar sagi maškim . ša₃ nibru{ki} . 4(u) udu . u₄ 1(u) 3(diš)-kam . 2(diš) gu₄ u₂ . 5(diš) ab₂ u₂ . 4(u) 3(diš) udu u₂  3(u) 3(diš) maš₂ u₂  1(u) 4(diš) ud₅ u₂  šu-gid₂ e₂-muhaldim  mu lu₂ maš₂-da-re-a-ke₄-ne-še₃  gešbun₂ er₂ su₃-a  ARAD₂-mu maškim  ša₃ uri₅{ki}-ma  1(u) maš₂-gal u₂  šu-gid₂ e₂-muhaldim  mu geme₂ dumu {d}inanna-ke₄-ne-še₃  u₄ ki-{d}utu ba-ak?-a  lugal-ma₂-gur₈-re maškim  ša₃ unu{ki}-ga  3(u) udu . mu x [...] . 1(diš) gu₄ u₂ . 6(diš) udu u₂ . 7(diš) maš₂-gal u₂ . mu lu₂ šuku-ra-ke₄-ne-še₃ . šu-gid₂ e₂-muhaldim . lugal-ma₂-gur₈-re maškim . ša₃ unu{ki}-ga . 1(diš) gu₄ 2(u) 3(diš) udu ʾ. u₄ 2(u) 5(diš)-kam ʾ. 1(u) ud₅ u₂ alan didli ʾ. ša₃ e₂ {d}inanna ʾ. uzu-a bala ʾ. siskur₂ gu-la  ša₃ unu[{ki}-ga]  1(u)  u₄ 2(u) 6(diš)-<kam>  1(diš) ab₂ u₂  5(diš) ud₅ u₂  mu aga₃-us₂ a tu₅-a ka e₂-gal-la kuₓ(KWU636)-ra-ne-še₃  1(diš) gu₄ u₂  5(diš) maš₂-gal u₂  4(diš) sila₄ . mu lu₂ šuku-ra-ke₄-ne-še₃ . šu-gid₂ e₂-muhaldim . lugal-ma₂-gur₈-re maškim . ša₃ unu{ki}-ga . 2(diš) gu₄ 1(u) 4(diš) udu . u₄ 2(u) 7(diš)-kam . 1(u) udu u₂ . šu-gid₂ e₂-muhaldim . mu lu₂ šuku-ra-ke₄-ne-še₃ . lugal-ma₂-gur₈-re maškim . ša₃ unu{ki}-ga . 1(u) udu . u₄ 2(u) 8(diš)-kam . 5(diš) udu u₂ {d}inanna . giri₃ a-bi₂-si₂-im-ti . {d}suen-a-bu-šu sagi maškim . 1(u) udu u₂ alan didli  ša₃ e₂ {d}inanna  lugal kuₓ(KWU636)-ra  1(u) 4(diš) ud₅ u₂  mu lu₂ šuku-ra-ke₄-ne-še₃  2(diš) ab₂ u₂  3(u) udu u₂  2(u) maš₂-gal u₂ . lugal nibru{ki}-še₃ du-ni ma₂-a ba-a-ga₂-ar . 2(diš) gu₄ 1(geš₂) 1(u) 8(diš) udu . u₄ 2(u) 9(diš)-kam . ša₃ nibru{ki} . u₄ 3(u)-kam  šu+nigin 7(diš) gu₄ u₂  šu+nigin 1(u) 1(diš) ab₂ u₂  šu+nigin 3(diš) ab₂ mu 3(diš)  šu+nigin 4(diš) ab₂ mu 2(diš)  šu+nigin 7(geš₂) 1(u) 2(diš) udu u₂  šu+nigin 2(u) 8(diš) u₈ u₂  šu+nigin 3(geš₂) 4(u) 8(diš) maš₂-gal u₂  šu+nigin 4(u) 3(diš) ud₅ u₂  šu+nigin 4(diš) sila₄ . šu+nigin₂ 2(u) 5(diš) gu₄ ab₂ hi-a . šu+nigin₂ 1(gešʾu) 3(geš₂) 5(u) 6(diš) udu maš₂ hi-a . ki ur-ku₃-nun-na-ta . ba-zi . giri₃ nu-ur₂-{d}suen dub-sar . iti ezem-mah . mu {d}šu-{d}suen . lugal uri₅{ki}-ma-ke₄ . e₂ {d}šara₂ umma{ki}-ka mu-du₃\n",
      "P124103\n",
      " 2(diš) gu₄  1(diš) gu₄ amar ga  2(diš) ab₂ 1(u) 2(diš) udu  8(diš) maš₂  šu-gid₂  2(diš) gu₄ 2(diš) ab₂ ba-uš₂  e₂-muhaldim-še₃  u₄ 2(u) 4(diš@t)-kam  ki in-ta-e₃-a-ta  ba-zi  iti šu-eš₅-ša  mu en-mah-gal-an-na en {d}nanna ba-hun  1(u) la₂ 1(diš) gu₄ 2(u) udu\n",
      "P142868\n",
      " 3(u) 1(diš) gu₄  1(diš) ab₂  iti diri še-sag₁₁-ku₅  5(u) 8(diš) gu₄  3(u) 3(diš) ab₂  iti u₅-bi₂-gu₇  1(diš) gu₄ niga  iti ezem-{d}nin-a-zu  2(geš₂) 4(diš) . mu us₂-sa ki-maš{ki} ba-hul . 1(geš₂) 6(diš) gu₄ . 4(u) 4(diš) ab₂ . iti a₂-ki-ti . 4(geš₂) 5(u) 1(diš) gu₄ . 1(geš₂) 1(u) 7(diš) ab₂ . iti ezem-{d}šul-gi . 1(diš) gu₄ niga . 1(geš₂) 3(u) la₂ 1(diš) gu₄ . 1(u) 5(diš) ab₂ . [iti šu]-eš₅-ša . [x] gu₄ . [...] x  2(geš₂) 4(u) 8(diš) gu₄  1(u) ab₂  iti ezem-mah  2(u) 5(diš) gu₄  iti ezem-an-na  1(geš₂) 2(u) 4(diš) gu₄  1(u) 4(diš) ab₂  iti ezem-me-ki-gal₂  4(u) gu₄ . iti še-sag₁₁-ku₅ . 1(gešʾu) 4(geš₂) 4(u) 3(diš) . mu {d}amar-{d}suen lugal . 1(geš₂) 1(u) 1(diš) gu₄ . 6(diš) ab₂ . iti maš-da₃-gu₇ . 8(diš) gu₄ . iti ses-da-gu₇ . 4(u) 4(diš) gu₄ . 8(diš) ab₂ . iti u₅-bi₂-gu₇ . 3(diš) gu₄ . 3(diš) ab₂ . iti# ki-siki-{d}nin-a-zu . [x] gu₄#  6(diš) gu₄  ki ṣe-lu-uš-{d}da-gan-ta  1(diš) gu₄  1(diš) ab₂  ki {d}nisaba-an-dul₃-ta  3(diš) gu₄  1(diš) ab₂  ki šu-da-da-ta  5(diš) gu₄ . 2(diš) ab₂ . ki šu-i₃-li₂-ta . 5(diš) gu₄ . 1(diš) ab₂ . ki i-din-e₂-a-ta . 2(diš) gu₄ . 1(diš) ab₂ . iti ezem-{d}šul-gi . 1(diš) gu₄ . iti šu-eš₅-ša . ki ur-{d}suen dumu u₃-sa₆-a-ta  4(diš) [ab₂]  ki zabar?-[dab₅?-ta]  iti ezem-mah#  3(diš) [gu₄]  1(u) la₂ 1(diš) [ab₂]  ki KA#-[...]  3(diš) [gu₄]  4(diš) [ab₂]  ki zabar#?-[dab₅?-ta] . 1(diš) [gu₄] . ki ur-sa₆#-[ga-ta] . 2(u) 5(diš) [gu₄] . 6(diš) [ab₂] . ki kal-[...] . iti šu-[eš₅-ša] . 2(geš₂) 4(u) 1(diš) . mu {d}amar-{d}suen# lugal-[am₃] . 4(diš) gu₄# . 1(diš) ab₂# . ki i-din-e₂-a-ta . iti u₅-bi₂-gu₇ . 1(diš) gu₄ . [...] . 1(diš) [...] . 1(diš) [...] . ki x-[...] . 3(u) 6(diš)# [gu₄] . 1(u) [ab₂] . kišib₃ ur-{d}x-[x] dumu ur-sa₆-ga . iti ki-siki-{d}nin-a-zu . 3(u) la₂ 1(diš) gu₄ . 2(u) la₂ 1(diš) ab₂ . kišib₃ a₂-na-na . iti šu-eš₅-ša ʾ. 3(u) 7(diš) gu₄ ʾ. 3(diš) ab₂ ʾ. kišib₃ lugal#?-[...] ʾ. 3(u) 8(diš) [gu₄] ʾ. 2(diš) ab₂# ʾ. kišib₃ u₄-[...] ʾ. 1(u) 4(diš) gu₄# ʾ. kišib₃ ensi₂ lu₂#? [ka]-zal-lu{ki} ʾ. 1(diš) gu₄ kišib₃ {d}EN-x-[...] ʾ. 2(u) gu₄ a-hu-[...] u₃ lu₂-{d}[...] mu gu₄ x-[...-še₃] ʾ. iti ezem-[...] ʾ. 1(u) 2(diš) [gu₄] . [x] x [...] . iti# šu-eš₅-ša . 5(geš₂) 1(u) 4(diš) . mu {d}amar-{d}suen lugal-[am₃] . 4(diš) ab₂ mu 2(aš) . iti maš-da₃-gu₇ . 2(u) 7(diš) gu₄ . 4(diš) ab₂ . kišib₃ uš-mu ʾ. a-ra₂ 1(diš)-kam ʾ. 1(diš) gu₄ kišib₃ lu₂-{d}nanna dumu inim-{d}šara₂ ʾ. 2(diš) gu₄ ʾ. kišib₃ ši-ha-lum nu-banda₃ ʾ. 1(diš) gu₄ ʾ. kišib₃ nin-a₂-zi-da ʾ. 1(diš) gu₄ ʾ. kišib₃ be-li₂-du₁₀ ra₂-gaba ʾ. 2(diš) gu₄ ʾ. kišib₃ ka₅-a-mu ʾ. 1(diš) gu₄ kišib₃ {d}šul-gi-ra₂!?-gaba ra₂-gaba lu₂ ur-nigar ʾ. 1(diš) gu₄ ʾ. kišib₃ im-da-du₁₀ nu-banda₃ . kišib₃ ka₅-a-mu . iti ki-siki-{d}nin-a-zu . u₃ iti ezem-{d}nin-a-zu . 1(geš₂) 4(u) 7(diš) . mu {d}amar-{d}suen lugal-e ur-bi₂-lum{ki} mu-hul . kišib₃ dab-ba . šu+nigin 5(diš) gu₄ niga . šu+nigin 3(gešʾu) 6(geš₂) 4(u) la₂ 1(diš) gu₄ . šu+nigin 1(gešʾu) 8(geš₂) 4(u) 3(diš) ab₂ ʾ. šu+nigin dusu₂-nita₂ ʾ. šu+nigin 2(diš) dusu₂ munus . nig₂-ka₉-ak . {d}en-lil₂-la₂ . ka la₂-a . giri₃ ur-ku₃-nun-na . iti diri še-sag₁₁-ku₅ . mu us₂-sa ki-maš{ki} ba-hul-ta . iti ezem-{d}nin-a-zu . mu {d}amar-{d}suen lugal-e ur-bi₂-lum{ki} mu-hul-še₃ . iti 3(u)-kam\n",
      "P467616\n",
      " 6(diš) gu₄ 6(diš) ab₂ [...]  zi-ga u₄ 1(diš)-[kam]  1(diš) gu₄ 3(diš) ab₂ u₄ 2(diš)#-[kam]  1(diš) gu₄ u₄ 3(diš)-[kam]  5(diš) gu₄ 1(diš) ab₂ u₄ 4(diš)-[kam]  3(diš) gu₄ 2(diš) ab₂ u₄ 5(diš)-[kam]  1(diš) ab₂ u₄ 6(diš)-kam  1(diš) gu₄ 3(diš) ab₂ u₄ 7(diš)-kam  2(diš) gu₄ 3(diš) ab₂ u₄ 8(diš)-kam . 4(diš) gu₄ u₄ 1(u) la₂ 1(diš)-kam giri₃ {d}en-lil₂-la₂ . 3(diš) gu₄ 7(diš) ab₂ u₄ 1(u)-kam . 1(diš) gu₄ 1(diš) ab₂ u₄ 1(u) 4(diš)-kam . 1(diš) gu₄ 2(diš) ab₂ u₄ 1(u) 5(diš)-kam . 4(diš) gu₄ u₄ 1(u) 6(diš)-kam . 4(diš) gu₄ u₄ 1(u) 7(diš)-kam . 2(diš) gu₄ u₄ 1(u) 8(diš)-kam . 1(diš) ab₂ u₄ 2(u) la₂ 1(diš)-kam  2(diš) gu₄ u₄ 2(u) 2(diš)-kam  1(diš) ab₂ u₄ 2(u) 5(diš)-kam  1(diš) gu₄ u₄ 2(u) 7(diš)-kam  2(diš) gu₄ u₄ 3(u) la₂ 1(diš)-kam  šu+nigin 4(u) 3(diš) [gu₄]  šu+nigin 3(u) 1(diš) [ab₂]  ki {d}en-lil₂-[la₂-ta]  ba-[zi]  iti ki-siki-{d}nin#-[a-zu] . mu {d}amar-{d}[suen] ur-bi₂-lum#[{ki} ba-hul]  1(geš₂) 1(u) 4(diš)\n",
      "\n",
      "Cluster 5\n",
      "========= \n",
      "\n",
      "P100328\n",
      " 4(diš) udu a-lum niga 3(diš)-kam us₂  8(diš) udu niga 4(diš)-kam us₂  1(diš) sila₄  be-li₂-a-ri₂-ik  2(diš) maš₂-gal niga 4(diš)-kam us₂  1(diš) sila₄  ṣe-lu-uš-{d}da-gan  4(diš) udu u₂  1(diš) sila₄ . ku-ba-ba-e . 4(diš) udu niga saga  6(diš) udu a-lum niga [saga]  2(u) udu a-lum niga saga us₂  3(u) udu a-lum niga 3(diš)-kam us₂  ba-ba-ti  u₄ 5(diš)-kam  mu-kuₓ(DU) lugal  in-ta-e₃-a i₃-dab₅  [giri₃] nu-ur₂-{d}suen dub-sar  iti# u₅-bi₂-gu₇ . mu us₂-sa {d}šu-{d}suen lugal uri₅{ki}-ma-ke₄ si-ma-num₂{ki} mu-hul  1(geš₂) 2(u) 1(diš) udu  nu-ur₂-{d}suen  dub-sar  dumu i-di₃-er₃-ra\n",
      "P100986\n",
      " [x] maš₂ niga 3(diš)-kam us₂  1(diš) udu niga 4(diš)-kam us₂  1(diš) {munus}aš₂-gar₃ niga 4(diš)-kam us₂  siskur₂ {d}inanna ša₃ e₂-gal  {d}nanna-igi-du sagi maškim  a₂-ge₆-ba-a  5(diš) udu niga gu₄-e-us₂-sa  5(diš) maš₂-gal niga gu₄-e-us₂-sa  i-zi-in-{d}da-gan . 3(diš) udu niga gu₄-e-us₂-sa . kur-bi-la-ak . lu₂ eb-la{ki}-me-eš₂ . 5(diš) udu niga gu₄-e-us₂-sa . 5(diš) maš₂-gal niga gu₄-e-us₂-sa . a-bu-du₁₀ lu₂ ma-ri₂{ki} . 5(diš) udu niga gu₄-e-us₂-sa . i-pi₂-iq-re-e-u₂ mar-tu ia₃-a-ma-di₃-um . iri-ne-ne-še₃ du-ni . ma₂-a ba-ne-gub . 3(diš) udu niga gu₄-e-us₂-sa . 2(diš) maš₂-gal niga gu₄-e-us₂-sa  i₃-u₃-ša dumu me-ša#-[nu-nu?] šimašgi  giri₃ ur-sukkal sukkal  ARAD₂-mu maškim  2(diš) udu niga saga us₂  8(diš) udu niga 3(diš)-kam us₂  a-bi₂-si₂-im-ti  tu-ra-am-{d}da-gan maškim  a₂ u₄!-te-na  u₄ 1(u) 4(diš)-kam . [ki a]-ba-{d}en-lil₂-gin₇-ta . [ba]-zi . [ša₃] nibru{ki} . giri₃ lu₂-{d}nin-šubur dub-sar . iti ezem-{d}šu-{d}suen . mu {d}šu-{d}suen lugal uri₅{ki}-ma-ke₄ na-ru₂-a-mah {d}en-lil₂ [{d}]nin-lil₂-ra [mu]-ne-du₃\n",
      "P101016\n",
      " 1(diš) udu niga saga  1(diš) maš₂-gal niga saga  1(diš) udu niga saga us₂  1(diš) udu niga 3(diš)-kam us₂  1(diš) udu niga 4(diš)-kam us₂  1(diš) udu niga gu₄-e-us₂-sa  an  1(diš) maš₂-gal niga saga  1(diš) udu niga saga us₂ . 1(u) udu niga gu₄-e-us₂-sa . {d}en-lil₂ . 2(diš) udu niga saga . 2(diš) udu niga saga us₂ . 1(diš) maš₂-gal niga 3(diš)-kam us₂ . 1(u) udu niga gu₄-e-us₂-sa . {d}nin-lil₂ . 1(diš) udu niga 3(diš)-kam us₂ . 1(diš) udu niga 4(diš)-kam us₂ . {d}gu-za {d}en-lil₂-la₂ . 1(diš) udu niga 3(diš)-kam us₂ . 1(diš) udu niga 4(diš)-kam us₂ . hur-sag-ga-lam-ma . 1(diš) udu niga 4(diš)-kam us₂ . AN a-ba-{d}en-lil₂-gin₇ . šu-nir {d}en-lil₂-la₂ . ša₃ nibru{ki} . 2(diš) udu niga saga . 1(diš) maš₂-gal niga saga us₂ . [x] udu niga gu₄-e-us₂-sa  {d}nin-lil₂  1(diš) udu niga 3(diš)-kam us₂  2(diš) udu niga 4(diš)-kam us₂  {d}nanna  1(diš) udu niga 3(diš)-kam us₂  1(diš) udu niga 4(diš)-kam us₂  {d}nin-ti₂-ug₅-ga  1(diš) udu niga 3(diš)-kam us₂  {d}nisaba . 1(diš) udu niga 3(diš)-kam us₂ . {d}en-lil₂-la₂ GI . 1(diš) udu niga 3(diš)-kam us₂ . 1(diš) udu niga 4(diš)-kam us₂ . e₂-gal mah . ša₃ e₂ {d}nin-lil₂-la₂ . 1(diš) udu niga . 1(diš) udu niga gu₄-e-us₂-sa . {d}nin-e₂-gi₄-a . 2(diš) udu niga 4(diš)-kam us₂ . 1(diš) udu niga . {d}nin-hur-sag . 2(diš) udu niga . {d}nin-pa-e₃ . ša₃ e₂ {d}nin-hur-sag . 2(diš) udu niga saga us₂ . 2(diš) udu niga du₆-ku₃ . 1(diš) udu niga 4(diš)-kam us₂ . {d}inanna ka-giri₃ . {d}šu-{d}[suen]  1(diš) udu niga [...]  1(diš) udu [...]  {d}PA-[...]  2(diš) udu niga [...]  1(diš) udu niga [...]  nig₂-[...]  {d}nin-[...]  1(diš) udu niga [...]  {d}[...] . 2(diš) udu [...] . {d}nin-[...] . 1(diš) udu niga [...] . 1(diš) udu [...] . 2(diš) udu niga [...] . {d}nin-sa₆-[...] . 1(diš) udu niga 4(diš)-kam [us₂] . 1(diš) udu [...] . {d}šu-{d}suen . 1(diš) udu niga x [...] . 1(diš) udu niga [...] . 1(diš) udu niga [...] . {d}EN-[...] . 1(diš) udu niga [...] . 1(diš) udu [...] . 1(diš) udu [...] . 1(diš) [...] . 2(diš) [...] . {d}nin-[...] . 2(diš) udu [...] . {d}x-x [...] . 1(diš) x x [...] . 1(diš) [...] . [...] . 1(diš) [...] . {d}[...] . 1(diš) udu niga gu₄-[e-us₂-sa] . {d}nisaba? . 1(diš) udu niga nig₂-x x . {d}nusku . 1(diš) udu niga gu₄-e-us₂-sa . nig₂-diri ʾ. {d}al-la gu-la ʾ. 1(diš) udu niga gu₄-e-us₂-sa ʾ. nig₂-diri ʾ. {d}[x]-x ʾ. ša₃ [x]-x-la [...] um? ʾ. 1(diš) udu [...] x ʾ. 1(diš) [...] ʾ. {d}nanna ʾ. 1(diš) [...] ʾ. {d}[...] ʾ. 1(diš) udu [...] ʾ. {d}ba-[...] ʾ. 1(diš) udu niga [...] ʾ. {d}nin-gir₂?-[su] ʾ. 2(diš) [...] ʾ. {d}en-[lil₂] ʾ. 2(diš) udu [...] ʾ. {d}nin-lil₂ ʾ. giri₃ a₂!-na-na ʾ. nig₂-dab₅ ezem [...] ʾ. 4(diš) x [...] ʾ. {d}šu-{d}[suen]  [x] udu niga  [...] niga  [...] a  [...] tum?  [...] iš?  [...] du?  [...] nisaba?  [...] ti  [a₂]-ge₆-ba-a . u₄ 7(diš)-kam . ki a-ba-{d}en-lil₂-gin₇-ta ba-zi . ša₃ nibru{ki} . giri₃ lu₂-{d}nin-šubur dub-sar . iti diri ezem-{d}me-ki-gal₂ . mu {d}šu-{d}suen lugal uri₅{ki}-ma-ke₄ na-ru₂-a-mah {d}en-lil₂ {d}nin-lil₂-ra mu-ne-du₃  2(geš₂) 2(u)\n",
      "P101400\n",
      " [...] 1(u) 1(diš) udu niga saga us₂  [x] gukkal niga 3(diš)-kam us₂  [x] udu niga 3(diš)-kam us₂  [x] maš₂-gal niga 4(diš)-kam us₂  {d}en-lil₂  1(diš) udu niga 4(diš)-kam us₂  {d}gu-za {d}en-lil₂-la₂  1(diš) udu niga 4(diš)-kam us₂  hur-sag-ga-lam-ma . ša₃ e₂ {d}en-lil₂-la₂ . [x] gukkal niga saga us₂ . [x] udu a-lum niga saga us₂ . [...] udu niga 3(diš)-kam us₂ . [...] niga 4(diš)-kam us₂ . [...] e₂ . [...] alan du₃ [...] . [...] x hu-ba-a . [...] x 1(diš) dusu x [...] . [...] 1(u) 4(diš) [mu-kuₓ(DU)] lugal . [...] 1(u) 5(diš)-kam . [ki] ša-x-e₂-ta . [ba]-zi . [giri₃ x]-an-ni dub-sar . [iti] ses-da-gu₇ u₄ . [mu {d}]šu-{d}suen lugal uri₅[{ki}-ma-ke₄ e₂ {d}šara₂] umma{ki}-ka [mu]-du₃\n",
      "P103805\n",
      " 3(diš) udu niga 1(diš) maš₂ niga  {d}en-lil₂  3(diš) udu niga 1(diš) maš₂ niga  {d}nin-lil₂  siskur₂ ša₃ e₂-a  2(diš) udu niga du₆-ku₃  1(diš) maš₂ niga {d}nin-hur-sag  1(diš) maš₂ niga {d}nusku  1(diš) maš₂ niga {d}nin-urta . 1(diš) maš₂ niga {d}inanna . 1(diš) maš₂ niga {d}nin-sun₂ . 1(diš) maš₂ niga {d}lugal-banda₃{da} . 1(diš) udu [niga] {d}nin-ti₂-ug₅-ga . [siskur₂] ge₆ a-ra₂ 1(diš)-kam . 9(diš)? udu niga 3(diš) maš₂ niga an . 8(diš) udu niga 2(diš) maš₂ niga {d}en-lil₂ . 8(diš) udu niga 2(diš) maš₂ niga {d}nin-lil₂ . ša₃ e₂ {d}en-lil₂-la₂ . 7(diš) udu niga 3(diš) maš₂ niga {d}nin-lil₂ . 1(diš) udu niga {d}en-lil₂-la₂-zi . 1(diš) udu niga {d}nin-ti₂-ug₅-ga . 1(diš) udu niga {d}nisaba  ša₃ e₂ {d}nin-lil₂-la₂  1(diš) udu niga 1(diš) maš₂ niga {d}nin-hur-sag  1(diš) udu niga 1(diš) maš₂ niga {d}nusku  1(diš) udu niga 1(diš) maš₂ niga {d}nin-urta  1(diš) udu niga 1(diš) maš₂ niga {d}inanna  1(diš) udu niga 1(diš) maš₂ niga {d}nin-sun₂  1(diš) udu niga 1(diš) maš₂ niga {d}lugal-banda₃{da}  1(diš) udu niga 1(diš) maš₂ niga {d}en-ki  1(diš) udu niga 1(diš) maš₂ niga {d}nin-ti₂-ug₅-ga . 2(diš) udu niga {d}en-lil₂ . 2(diš) udu niga {d}nin-lil₂ . giri₃ {d}na-na-a e₂ {d}en-lil₂-la₂-še₃ tu-ra . {d}en-lil₂-ra {d}šul-gi-re kaš-de₂-a . 2(diš) udu niga 2(diš) maš₂ niga {geš}kiri₆-mah . 1(diš) udu niga siskur₂ {d}inanna ša₃ {geš}kiri₆ . {d}nanše-GIR₂@g?-gal maškim . 1(diš) udu niga {d}na-na-a . er₃-ra-na-da maškim? . iti u₄ 7(diš) ba-zal . šu+nigin# 4(diš) udu niga 2(u) 5(diš) maš₂ niga . zi-ga ki na-lu₅ . iti ezem-me-ki-gal₂ . mu ur-bi₂-lum{ki} ba-hul\n",
      "P126109\n",
      " 1(diš) udu niga 3(diš)-kam us₂  1(diš) udu niga 4(diš)-kam us₂  1(diš) maš₂-gal niga 4(diš)-kam us₂  {d}nin-lil₂  lugal ku₄?-ra  a₂-ge₆-ba-a  iti u₄ 1(u) 7(diš) ba-zal  ki {d}en-lil₂-zi-ša₃-gal₂-ta  ba-zi  iti ki-siki-{d}nin-a-zu  mu us₂-sa si-[ma]-num₂{ki} ba-hul  {d}šu-{d}suen  lugal kal-ga  lugal uri₅{ki}-ma  lugal an ub-da limmu₂-ba  {d}šul-gi-iri-mu sukkal  ra₂-gaba  ARAD₂-zu\n",
      "P126542\n",
      " 1(diš) udu niga saga  1(diš) udu niga 3(diš)-kam us₂  1(diš) maš₂-gal niga 4(diš)-kam us₂  {d}en-lil₂  1(diš) udu niga saga us₂  1(diš) udu niga 3(diš)-kam us₂  {d}nin-lil₂  lugal ku₄?-ra  2(diš) udu niga 3(diš)-kam us₂  {d}nanna  siskur₂ ša₃ e₂-gal  iti u₄ 1(u) 1(diš) ba-zal  ki a-hu-we-er-ta  ba-zi  giri₃ {d}šul-gi-al-mah dub-sar  iti a₂-ki-ti  mu {d}šu-{d}suen lugal uri₅{ki}-ma-ke₄ si-ma-num₂{ki} mu-hul  7(diš) udu  {d}šul-[gi]-al-mah  dub-[sar]  [dumu ...]\n",
      "P142809\n",
      " 1(diš) udu niga 1(diš) maš₂-gal niga  {d}en-lil₂  1(diš) udu niga {d}gu-za  1(diš) udu niga 1(diš) maš₂-gal niga  {d}nin-lil₂  a₂ gu₂ zi-ga  2(diš) udu niga {d}en-lil₂  1(diš) udu niga {d}gu-za  1(diš) maš₂-gal niga ki puzur₄-x-x  4(diš) udu niga [...]  a₂ x-x-na  a-tu maškim  1(u) [...]  [...]  ki# [...]  x ki [...]  x x [...]  iti [...] . x x [...] x x . iti ezem-mah . mu en-unu₆-gal {d}inanna# ba-hun  3(u) 1(diš)\n",
      "\n",
      "Cluster 6\n",
      "========= \n",
      "\n",
      "P101002\n",
      " 3(diš) udu  1(diš) maš₂  u₄ 3(u)-kam  ki na-lu₅-ta  {d}šul-gi-iri-mu  šu ba-ti  iti a₂-ki-ti  mu {d}gu-za {d}en-lil₂-la₂ ba-dim₂\n",
      "P107878\n",
      " 1(diš) maš₂-gal  ba-uš₂  u₄ 4(diš)-kam  ki na-lu₅-ta  {d}šul-gi-iri-mu  šu ba-ti  iti a₂-ki-ti  mu hu-uh₂-nu-ri{ki} ba-hul\n",
      "P124191\n",
      " 1(diš) gukkal  1(diš) maš₂-gal  ba-uš₂  u₄ 5(diš@t)-kam  ki na#-lu₅-ta  {d}šul-gi-iri-mu  šu ba-ti  iti šu-eš-ša  mu en eridu{ki} ba-hun  2(diš) udu\n",
      "P124264\n",
      " 1(diš) maš₂-gal  ba-uš₂#  u₄# 2(u)# 4(diš)-kam  ki# [tah]-ša#-tal-ta  {d}šul-gi-iri-mu  šu ba-ti  iti a₂-ki-ti  mu ša-aš-ru{ki} ba-hul  1(diš)\n",
      "P134996\n",
      " 4(diš) udu  1(diš) sila₄  1(diš) {munus}aš₂-gar₃  ba-uš₂ u₄ 2(u) 2(diš)-kam  ki na-lu₅-ta  {d}šul-gi-iri-mu  šu ba-ti  iti ki-siki-{d}nin-a-zu  mu hu-uh₂-nu-ri{ki} ba-hul  1(diš) udu\n",
      "\n",
      "Cluster 7\n",
      "========= \n",
      "\n",
      "P101005\n",
      " 1(diš) udu  1(u) 5(diš) maš₂-gal  u₄ 1(u) 3(diš)-kam  ki ab-ba-sa₆-ga-ta  na-lu₅ i₃-dab₅  iti šu-eš₅-ša  mu hu-uh₂-nu-ri{ki} ba-hul  1(geš₂) 1(u) 5(diš)\n",
      "P101006\n",
      " 2(u) 7(diš) udu  4(diš) sila₄  5(u) 5(diš) maš₂-gal  u₄ 3(u)-kam  ki ab-ba-sa₆-ga-ta  in-ta-e₃-a  i₃-dab₅  iti šu-eš₅-ša  mu hu-uh₂-nu-ri{ki} ba-hul  1(geš₂) 3(u)\n",
      "P101008\n",
      " 4(diš) sila₄  u₄ 2(u) 5(diš)-kam  ki ab-ba-sa₆-ga-ta  in-ta-e₃-a i₃-dab₅  iti ezem-mah  mu hu-uh₂-nu-ri{ki} ba-hul  4(diš)\n",
      "P101009\n",
      " 2(diš) ud₅  1(u) 7(diš) maš₂  u₄ 2(u) 8(diš)-kam  ki ab-ba-sa₆-ga-ta  in-ta-e₃-a  i₃-dab₅  iti ezem-mah?  mu hu-uh₂-nu-ri{ki} ba-hul  2(u) la₂ 1(diš)\n",
      "P101010\n",
      " 1(u) la₂ 1(diš) udu  2(u) sila₄  8(diš) maš₂  u₄ 2(u) 8(diš)-kam  ki ab-ba-sa₆-ga-ta  in-ta-e₃-a i₃-dab₅  iti ezem-mah  mu hu-uh₂-nu-[ri{ki}] ba-hul  3(u) 7(diš)\n",
      "P124025\n",
      " 8(diš) udu  7(diš) sila₄#  2(diš) maš₂#  u₄# 2(u) 1(diš)-kam#  ša₃ uri₅{ki}-ma#  ki ab-ba-sa₆-ga-ta  in-ta-e₃#-a# i₃-dab₅#  iti ezem-an-na  mu en-unu₆-gal# {d}inanna unu{ki} ba-hun  1(u) 7(diš)\n",
      "P124071\n",
      " 2(diš) udu niga  1(diš) sila₄  u₄ 2(u) 4(diš@t)-kam  ki ab-ba-sa₆-ga-ta  na-lu₅  i₃-dab₅  iti ezem-an-na  mu hu-uh₂-nu-ri{ki} ba-hul  3(diš)\n",
      "P124539\n",
      " 8(diš) udu 1(u) 2(diš) u₈  2(diš) maš₂-gal  šu-gid₂  3(diš) udu 5(diš) ud₅  ba-uš₂  e₂-muhaldim-še₃  u₄ 1(u) la₂ 1(diš)-kam  ki in-ta-e₃-a-ta ba-zi  iti ezem-mah  mu hu-uh₂-nu-ri{ki} ba-hul  3(u)\n",
      "P407077\n",
      " 1(u) 2(diš) udu  5(diš) sila₄  8(diš) maš₂  u₄ 1(u) 1(diš)-kam  ki ab-ba-sa₆-ga-ta  in-ta-e₃-a  i₃-dab₅  iti ezem-an-na  mu {d}gu-za {d}en-lil₂-la₂ ba-dim₂  2(u) 5(diš)\n",
      "P407141\n",
      " 1(diš) sila₄  u₄ 1(u) 4(diš)-kam  ki ab-ba-sa₆-ga-ta  in-ta-e₃-a  i₃-dab₅  iti a₂-ki-ti  mu ša-aš-ru{ki} ba-hul  1(diš)\n",
      "\n",
      "Cluster 8\n",
      "========= \n",
      "\n",
      "P101300\n",
      " 2(diš) sila₄  ki ur-ku₃-nun-na-ta  du₁₁-ga  i₃-dab₅  iti ezem-mah  mu en {d}inanna maš₂-e i₃-pa₃  du₁₁-ga dub-sar  dumu lu₂-{d}nin-gir₂-su  sipa na-gab₂-tum\n",
      "P101325\n",
      " 8(diš) udu  ki ka₅-a-mu-ta  du₁₁-ga i₃-dab₅  iti ezem-{d}nin-a-zu  mu ma₂-dara₃-abzu {d}en-ki ba-ab-du₈  du₁₁-ga dub-sar  dumu lu₂-{d}nin-gir₂-su  sipa na-gab₂-tum\n",
      "P101328\n",
      " 4(diš) udu  8(diš) maš₂  ki ka₅-a-mu-ta  du₁₁-ga  i₃-dab₅  giri₃ al-la-mu  iti ezem-me-ki-gal₂  mu ma₂ {d}en-ki-ka ba-ab-du₈  du₁₁-ga dub#-[sar]  dumu lu₂-[{d}nin-gir₂-su]  sipa na-[gab₂]-tum\n",
      "P101398\n",
      " 1(diš) udu  kišib₃ {d}utu-bar-ra unu₃  ki ur-mes-ta  ba-zi  iti ezem-{d}šul-gi  mu ma₂-dara₃-abzu ba-ab-du₈  udu  du₁₁-ga dub-sar  dumu lu₂-{d}nin-[gir₂-su]  sipa na-gab₂-[tum]\n",
      "P104312\n",
      " iti diri [...]-x  [mu ...]  du₁₁-ga dub-sar  dumu lu₂-{d}nin-gir₂-su  sipa na-gab₂-tum\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print clusters\n",
    "clusters = {}\n",
    "for c, i in enumerate(labels1):\n",
    "    if i == -1:\n",
    "        continue\n",
    "    elif i in clusters:\n",
    "        clusters[i].append(trans_list[c] )\n",
    "    else:\n",
    "        clusters[i] = [trans_list[c]]\n",
    "\n",
    "i= 0\n",
    "for c in clusters:\n",
    "    print(\"Cluster\", i)\n",
    "    print(\"=========\",\"\\n\")\n",
    "    for trans in clusters[c]:\n",
    "        print(trans_dict[trans].p_id)\n",
    "        print(trans)\n",
    "    print()\n",
    "    i += 1\n",
    "    \n",
    "# Brief analysis: number of clusters depends on eps and ngram range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all files to get all Drehem transactions\n",
    "def read_files(subdir, ids, reverse=False):\n",
    "    transactions = list()\n",
    "    for i in range(1, 16):\n",
    "        file_name = \"\"\n",
    "        if i < 10:\n",
    "            file_name += subdir + \"p00\" + str(i) + \".atf\"\n",
    "        else:\n",
    "            file_name += subdir + \"p0\" + str(i) + \".atf\"\n",
    "        \n",
    "        curr_transaction = None\n",
    "        \n",
    "        with open(file_name, encoding=\"utf8\") as file:\n",
    "            print(\"Opening:\", file_name)\n",
    "            for line in file:\n",
    "                line = line.strip()\n",
    "                if line.startswith('&P'):\n",
    "                    p_id = line.split()[0][1:]\n",
    "                    #print(p_id)\n",
    "                    if (not reverse and p_id in ids):\n",
    "                        ids.remove(p_id)\n",
    "                        if curr_transaction:\n",
    "                            transactions.append(curr_transaction)\n",
    "                        transaction = Transaction(p_id)\n",
    "                        curr_transaction = transaction\n",
    "                    elif (reverse and p_id not in ids and len(transactions) <= 200):\n",
    "                        if curr_transaction:\n",
    "                            transactions.append(curr_transaction)\n",
    "                        transaction = Transaction(p_id)\n",
    "                        curr_transaction = transaction\n",
    "                    else:\n",
    "                        if curr_transaction:\n",
    "                            transactions.append(curr_transaction)\n",
    "                        curr_transaction = None\n",
    "                else:\n",
    "                    if curr_transaction:\n",
    "                        curr_transaction.lines.append(line)\n",
    "        \n",
    "        if curr_transaction:\n",
    "            transactions.append(curr_transaction)\n",
    "    \n",
    "    #print(ids)\n",
    "    #assert len(ids) == 0\n",
    "    print(\"Number of transactions:\", len(transactions))\n",
    "    return transactions\n",
    "\n",
    "# Return the IDs of docs to annotate\n",
    "def get_drehem_ids(file):\n",
    "    lst = list()\n",
    "    with open(file, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            lst.append(\"P\" + line)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P125693', 'P131063', 'P103742', 'P118642', 'P337724', 'P212008', 'P103154', 'P105823', 'P390986', 'P115492']\n",
      "Opening: raw-data/p001.atf\n",
      "Opening: raw-data/p002.atf\n",
      "Opening: raw-data/p003.atf\n",
      "Opening: raw-data/p004.atf\n",
      "Opening: raw-data/p005.atf\n",
      "Opening: raw-data/p006.atf\n",
      "Opening: raw-data/p007.atf\n",
      "Opening: raw-data/p008.atf\n",
      "Opening: raw-data/p009.atf\n",
      "Opening: raw-data/p010.atf\n",
      "Opening: raw-data/p011.atf\n",
      "Opening: raw-data/p012.atf\n",
      "Opening: raw-data/p013.atf\n",
      "Opening: raw-data/p014.atf\n",
      "Opening: raw-data/p015.atf\n",
      "Number of transactions: 14594\n"
     ]
    }
   ],
   "source": [
    "all_ids = get_drehem_ids(\"drehem_p_ids.txt\")\n",
    "print(all_ids[:10])\n",
    "all_transactions = read_files(\"raw-data/\", all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "mapping = {}\n",
    "labs = []\n",
    "\n",
    "for t in all_transactions:\n",
    "    t.get_lemmatization()\n",
    "    labs.append(t.set_label())\n",
    "    lemma = \" \".join(t.get_sumerian_lemma())\n",
    "    data.append(lemma)\n",
    "    if lemma in mapping:\n",
    "        mapping[lemma].append(t)\n",
    "    else:\n",
    "        mapping[lemma] = [t]\n",
    "        \n",
    "# Predict\n",
    "X_new_counts = uni_and_bigram_vectorizer.transform(data)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "uni_and_bigram_prediction = uni_and_bigram_classifier.predict(X_new_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'udu kišib ki lugal kalag lugal lugal an anubda limmu dubsar dumu arad' => not queen\n",
      "'udu niga sila ga uš ud ki šu teŋ itud mu u hulu' => not queen\n",
      "'sila sila mu.DU zabardab maškim u udu maš uš ekišibak ud lal ki itud mu us hulu' => not queen\n",
      "'mašgal niga udu uš ud šag ki šu teŋ itud mu lugal' => not queen\n",
      "'udu a sag udu niga mašgal niga udu sila ga kir ga uš ud ki šu teŋ itud mu lugal' => not queen\n",
      "'udu niga sila niga udu sila ensik sila ensik sila mu.DU itud mu en maš pad ud' => not queen\n",
      "'mašgal niga egia ensik ragaba maškim itud ud lal zal ki ŋiri dubsar itud mu en huŋ udu' => not queen\n",
      "'amar mašda mašda amar amar mašda sila amar mašda maš sila ensik mu.DU dab itud gu mu us hulu ud' => not queen\n",
      "'mašgal ki ensik dab itud mu huŋ udu' => not queen\n",
      "'sila zabardab sila ensik sila ensik mu.DU dab itud akiti mu u mada ud hulu ud' => not queen\n",
      "'mašgal niga lu maškim itud ud zal ki itud mu lugal hulu' => not queen\n",
      "'gud ab mu.DU lugal ki bala zig ensik dab ziga itud mu en maš pad' => not queen\n",
      "'lal udu udu u u sila gub sila gub šugid udu a gukkal lal maš gub uzud ašgar ki ensik ud mu.DU dab itud mu du' => not queen\n",
      "'udu sadug šag udu uš mu sipad šu teŋ ki itud mu us hulu' => not queen\n",
      "'udu sadug šag udu u maš uš mu urgir sipad urgir šu teŋ ki itud mu us hulu' => not queen\n",
      "'udunita u kir ur itud uzud kir ur udunita mašgal itud akiti sadug u mu e du' => queen\n",
      "'udu u mašgal u uš sadug urgir sipad urgir šu teŋ ugula ki ŋiri dubsar itud mu lugal dim udu' => not queen\n",
      "'sila sila mu.DU sila sila mu.DU en sila mu.DU zabardab maškim gud niga u uš emuhaldim ud ziga itud mu en maš pad' => not queen\n",
      "'udu mašgal udu mašgal šagia maškim šag mu.DU ud ki ŋiri dubsar itud mu du' => not queen\n",
      "'šugid emuhaldim mu gardu sukkal maškim itud ud zal ki itud mu en huŋ' => not queen\n",
      "'u uzud šugid emuhaldim mu gardu maškim šag ašag ud ki ŋiri dubsar itud mu en huŋ' => not queen\n",
      "'durah munus sila sila sila sila sila ud mu.DU dab itud mu huŋ' => not queen\n",
      "'sila ud ki dab itud mu huŋ' => not queen\n",
      "'sila mu.DU zabardab maškim ud ki itud mu u mada ud hulu' => not queen\n",
      "'mašda ekišibak mu.DU ud ki itud mu u mada ud hulu' => not queen\n",
      "'mašgal babbar ud ki dab ŋiri itud mu huŋ udu' => not queen\n",
      "'sila ga kir ga maš ga ašgar ga utuda ud ki itud mu lugal' => not queen\n",
      "'udu niga udu aslum ud lal ki dab itud mu huŋ' => not queen\n",
      "'udu niga sag us gukkal niga u niga udu uzud sila kir uš ud ki šu teŋ itud mu lugal' => not queen\n",
      "'sila ga kir ga maš ga ašgar ga utuda ud šag dab itud mu lugal' => not queen\n",
      "'gud udu u mu.DU kurušda dab itud mu us hulu' => queen\n",
      "'udu sila maš sila ga maš ga uš ud ki šu teŋ mu dim' => not queen\n",
      "'ab udu mašgal uzud sila ga uš ud ki šu teŋ itud mu huŋ gud udu' => not queen\n",
      "'sila maš sila mu.DU dab itud mu hulu' => queen\n",
      "'udu maš mu.DU dab itud mu hulu' => queen\n",
      "'gud niga šag ud ki dab itud mu huŋ gud' => not queen\n",
      "'udu niga sadug kag eš udu niga sadug kag ŋipar udu u itud ud zal ziga šag itud mu us hulu' => queen\n",
      "'gud niŋgur ugu de itud ud zal gud de dug mu lugal pad igi igi damgar igi mu en maš pad dumu' => not queen\n",
      "'suhub eban ki ensik erin agaʾus lugal šu teŋ nubanda šag ŋiri mu en huŋ' => not queen\n",
      "'gud ab gud amar ga ab sila sila amar mašda udu mašgal sila amar mašda sila en sila amar mašda sila muhaldim sila amar mašda mu.DU itud mu u hulu ud' => not queen\n",
      "'gud udu mu agaʾus ud gud udu udu uš lugal du ma ŋar ud ki itud mu lugal lugal kalag lugal lugal an anubda limmu dubsar dumu arad' => not queen\n",
      "'zidgu sadug ki itud mu e du' => not queen\n",
      "'irsaŋ itud ud zal irsaŋ itud ud zal uš egal ziga mu us e du' => queen\n",
      "'gud ab emuhaldim ud gud ab ud gud ab ud gud ab ud gud ab ud gud ud gud ab ud ab ud gud ab ud lal gud ab ud gud ab ud gud ud gud ab ud gud ud gud ab ud gud ab ud gud ab ud gud ab ud gud ud emuhaldim šuniŋin gud šuniŋin ab ki itud akiti mu lugal hulu gud ab hi' => not queen\n",
      "'udunita mašgal kišib udunita kišib dumu ki šu teŋ itud itud mu dumu' => not queen\n",
      "'udu maš hi ki itud itud itud mu lugal mada hulu lugal kalag lugal lugal an anubda limmu dubsar dumu arad' => not queen\n",
      "'udu niga udu sadug kud bala ensik ki ud lal mu.DU dab itud mu en huŋ' => not queen\n",
      "'sila sila mu.DU en sila udunita lu kiŋgia lu mu u hulu' => not queen\n",
      "'udu maš sila udu maš sila sila sila sila šag e sila sila sila sila a sila maškim ud šuniŋin ab mu udu šuniŋin lal udu maš bala ensik ki itud mu lugal' => not queen\n",
      "'udu aslum niga us udu niga us sila mašgal niga us sila udu u sila udu niga sag udu aslum niga sag udu aslum niga sag us udu aslum niga us ud mu.DU lugal dab ŋiri dubsar itud mu us lugal hulu udu dubsar dumu' => not queen\n",
      "'kir gub udu udu mašgal ŋiri uzud mašgal ŋiri udu mašgal ŋiri mašgal mašgal ŋiri u u kir gub udu udu ŋiri uzud lal mašgal ŋiri udu ŋiri mašgal mašgal ŋiri šuniŋin udu udu šuniŋin u u šuniŋin kir gub mašgal šuniŋin mašgal šuniŋin uzud ki dab itud akiti mu en huŋ' => not queen\n",
      "'gukkal ŋešdu u gukkal lal udu hursaŋ u hursaŋ mu.DU lugal šabra dab ki itud mu en huŋ' => not queen\n",
      "'gukkal gukkal ŋešdu gin gukkal gukkal il udu MAR.TU sila niga sila sila ensik sila sila niga šabra sila sila dubsar sila udu aslum ŋešdu gukkal maš sila sila šag ud mu.DU dab itud akiti mu dim' => not queen\n",
      "'udu niga sag us udu niga us udu niga us udu u zig ama ud ŋen maškim a ud ki ŋiri šarrabdu itud mu lugal dim' => not queen\n",
      "'gud lal udu lal maš situm mu us hulu' => not queen\n",
      "'udu udu maškim itud ud lal zal ziga ki itud mu hulu' => not queen\n",
      "'udu sila sila ga uš ud ki šu teŋ itud mu us hulu' => not queen\n",
      "'gud niga amar kud mu niga siškur gula e itud ud zal ki dab itud mu u hulu' => not queen\n",
      "'gud niga amar gud udu niga gukkal niga sila kir niga mašgal niga uzud niga ašgar udu mašgal sila uš ud ki šu teŋ itud mu us u hulu' => not queen\n",
      "'ud lal uš ki šu teŋ itud mu lugal hulu' => not queen\n",
      "'udu niga sila mašgal uš ud ki šu teŋ itud mu lugal guza dim' => not queen\n",
      "'sa gi še nubanda ŋiri' => not queen\n",
      "'sa gi sadug ki itud mu us bad du' => not queen\n",
      "'sa gi' => not queen\n",
      "'gu gi' => not queen\n",
      "'sa gi ugula' => not queen\n",
      "'ŋuruš ud ma gid ŋuruš nagar ud ki kišib mu hulu' => not queen\n",
      "'ŋuruš ud ki guzala šu teŋ mu ara lal hulu' => not queen\n",
      "'ŋuruš ud kisur ašag gub ugula kišib mu lugal' => not queen\n",
      "'ŋuruš ud ašag manu še ziga ŋiri mu us hulu' => not queen\n",
      "'ŋuruš dubsar ud gub ugula dab mu hulu' => not queen\n",
      "'še lugal kaš kišib bisaŋdubak' => not queen\n",
      "'še gur ziz gur šu teŋ' => not queen\n",
      "'ziz gur sisa kib gur ki šu teŋ' => not queen\n",
      "'še gur lugal ziz gur kišib arad ki še šuniŋin še gur mu.DU itud mu hulu' => not queen\n",
      "'sila še gur mu.DU u mu hulu' => not queen\n",
      "'še gur sadug itud ki kišib mu hulu' => not queen\n",
      "'šuʾi malah idu nukirik nukirik agaʾus' => not queen\n",
      "'ŋiri še gur kišib' => not queen\n",
      "'še gur lugal šag gur kišib gur kišib' => not queen\n",
      "'še gur lugal maš tuku mu ki damgar šu teŋ' => not queen\n",
      "'sila še gur lugal a ma huŋ še gur esir še gur miriza ki šu teŋ mu bad du' => not queen\n",
      "'še gur a ma huŋ id e ki šabra šu teŋ mu hulu' => not queen\n",
      "'dabin gu sag kišib' => not queen\n",
      "'kaš du gur lugal ziga ki' => not queen\n",
      "'kaš sag sadug lal sila du dirig sag ud ki' => not queen\n",
      "'du kag sag duga ud lal lal sila du dirig sag du dirig sag dug ud du sadug sag du dirig ud ud tuku ki kišib mu hulu' => not queen\n",
      "'zidgu lugal zid kaš dida sag kaš dida du kud kunzida šaggal maš mu' => not queen\n",
      "'sila zulum kaš dida du kaš dida sag sila kaš du dabin sila inun sila gaʾar sila inun dug sila dug sila bappir dug sila eša zid zidgu du sila inun sila gaʾar sila bappir dug siškur šag e zid gur eša zid mu lugal' => not queen\n",
      "'ara ma gur še gu mana mangaga sila dabin gur kaš du gur sila eša sila zidsig ki šu teŋ mu hulu' => not queen\n",
      "'sila babbar ŋi šelu gur gugal gur sila ki lu tir mu us ara hulu' => not queen\n",
      "'zulum gur lugal šu teŋ kišib mu e du' => not queen\n",
      "'udu maš kišib udu maš kišib ki dab mu us ara hulu' => not queen\n",
      "'u bar sug udunita sila dumu abba dab dab ki kaš kag kešed mu hulu' => not queen\n",
      "'udunita uš ki šu teŋ mu bad du' => not queen\n",
      "'šu gud anše deg gud ŋiri unud u sipad anše ki kaš kišib mu hulu' => not queen\n",
      "'gud niga sadug gud niga niŋ ŋeš tag lugal ara ŋiri gud niga sadug ki kaš mu lugal hulu' => not queen\n",
      "'ab ga gud ga udu sila maš nesaŋ udu mu mašda šeŋbar niŋdab ki kaš mu hulu' => not queen\n",
      "'udu u uzud mašgal maš sadug babbar ki dab mu lugal hulu' => not queen\n",
      "'maš maš magur ŋiri kaš kaš dab mu kug guza dim' => not queen\n"
     ]
    }
   ],
   "source": [
    "for doc, category in zip(data[:100], uni_and_bigram_prediction[:100]):\n",
    "    print('%r => %s' % (doc, category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05543373989310676\n"
     ]
    }
   ],
   "source": [
    "# Percentange of Queen transactions\n",
    "print(len([i for i in uni_and_bigram_prediction if i == \"queen\"])/len(uni_and_bigram_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "queens = [data[i] for i in range(len(uni_and_bigram_prediction)) if uni_and_bigram_prediction[i] == \"queen\"]\n",
    "\n",
    "# This code is outdated; it relied on a one-to-one mapping of lemmatized lines to PIDs, but there are some duplicate lines.\n",
    "\n",
    "# with open(\"predicted_queen_v2.txt\", 'w', encoding=\"utf8\") as f:\n",
    "#     for q in queens:\n",
    "#         qu = mapping[q]\n",
    "#         f.write(qu.p_id+\"\\n\")\n",
    "#         for line in qu.lemmas.keys():\n",
    "#             f.write(line+\"\\n\")\n",
    "#         f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Support Vector Machine\n",
    "Good for classification and when you have small datasets (<1000 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9297658862876255"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "text_clf = Pipeline([\n",
    "        ('vect', CountVectorizer(analyzer=\"word\", ngram_range=(1, 2),token_pattern='(?u)\\\\b\\\\w+\\\\b')),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42))])\n",
    "\n",
    "text_clf.fit(training_data, training_labels)\n",
    "predicted = text_clf.predict(test_data)\n",
    "np.mean(predicted == test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_v2 = text_clf.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05961353981088118\n",
      "['not queen' 'not queen' 'not queen' 'not queen' 'not queen' 'not queen'\n",
      " 'not queen' 'not queen' 'not queen' 'not queen']\n"
     ]
    }
   ],
   "source": [
    "print(len([i for i in predict_v2 if i == 'queen'])/len(predict_v2))\n",
    "print(predict_v2[:10])\n",
    "#print(all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "uni_bi_vect = CountVectorizer(analyzer = \"word\",\n",
    "                              ngram_range = (1,2),\n",
    "                              token_pattern='(?u)\\\\b\\\\w+\\\\b')\n",
    "\n",
    "# Train\n",
    "X_train_counts = uni_bi_vect.fit_transform(training_data) # Learn the vocabulary dictionary and return term-document matrix.\n",
    "\n",
    "# Get TF-IDF\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      "{'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Classifier\n",
    "# gamma = how far single training example influence can reach\n",
    "# low values = far influence\n",
    "# high values = close influence\n",
    "# c = tradeoff of misclassification vs simplicity\n",
    "# low values = smooth decision surface\n",
    "# high values = classify everything correctly\n",
    "\n",
    "params = [{'kernel': ['rbf', 'linear'],\n",
    "          'gamma': [1e-4, 1e-3, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 100],\n",
    "          'C': [1, 5, 10, 50]}]\n",
    "uni_bi_clf = GridSearchCV(svm.SVC(decision_function_shape='ovr'), params)\n",
    "# uni_bi_clf = GridSearchCV(svm.SVC(decision_function_shape='ovr'), params, cv = 10)\n",
    "uni_bi_clf.fit(X_train_tfidf, training_labels)\n",
    "print(\"Best parameters found:\")\n",
    "print(uni_bi_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9331103678929766\n",
      "Recall:  0.9383199079401611\n",
      "Precision:  0.9024725274725274\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "X_new_counts = uni_bi_vect.transform(test_data)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "uni_bi_pred = uni_bi_clf.predict(X_new_tfidf)\n",
    "\n",
    "print(\"Accuracy: \", np.mean(uni_bi_pred == test_labels))\n",
    "print(\"Recall: \", str(metrics.recall_score(test_labels, uni_bi_pred, [\"queen\", \"not queen\"], average=\"macro\")))\n",
    "print(\"Precision: \", str(metrics.precision_score(test_labels, uni_bi_pred, [\"queen\", \"not queen\"], average=\"macro\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage Queens' Texts Predicted\n",
      "0.0650267233109497\n"
     ]
    }
   ],
   "source": [
    "X_all_counts = uni_bi_vect.transform(data) \n",
    "X_all_tfidf = tfidf_transformer.transform(X_all_counts)\n",
    "uni_bi_pred_v2 = uni_bi_clf.predict(X_all_tfidf)\n",
    "print(\"Percentage Queens' Texts Predicted\")\n",
    "print(len([i for i in uni_bi_pred_v2 if i == 'queen'])/len(uni_bi_pred_v2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fold 0\n",
      "Best parameters found:\n",
      "{'C': 5, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Starting fold 1\n",
      "Best parameters found:\n",
      "{'C': 5, 'gamma': 0.0001, 'kernel': 'linear'}\n",
      "Starting fold 2\n",
      "Best parameters found:\n",
      "{'C': 1, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "Starting fold 3\n",
      "Best parameters found:\n",
      "{'C': 5, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Starting fold 4\n",
      "Best parameters found:\n",
      "{'C': 5, 'gamma': 1, 'kernel': 'rbf'}\n",
      "Starting fold 5\n",
      "Best parameters found:\n",
      "{'C': 5, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Starting fold 6\n",
      "Best parameters found:\n",
      "{'C': 10, 'gamma': 0.05, 'kernel': 'rbf'}\n",
      "Starting fold 7\n",
      "Best parameters found:\n",
      "{'C': 1, 'gamma': 0.0001, 'kernel': 'linear'}\n",
      "Starting fold 8\n",
      "Best parameters found:\n",
      "{'C': 5, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Starting fold 9\n",
      "Best parameters found:\n",
      "{'C': 1, 'gamma': 0.0001, 'kernel': 'linear'}\n",
      "Total Accuracy:  0.9514563106796117\n",
      "Average Accuracy:  0.9517089018843405\n",
      "Total Recall:  0.9507715912779204\n",
      "Average Recall:  0.9510029186499775\n",
      "Total Precision:  0.9522447795480247\n",
      "Average Precision:  0.9537631113274667\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "n1 = len(queen_data)\n",
    "n2 = len(non_queen_data)\n",
    "q_fold_size = [i * (n1 // 10) for i in range(10)] + [n1] \n",
    "nq_fold_size = [i * (n2 // 10) for i in range(10)] + [n2] \n",
    "all_pred = []\n",
    "all_true_lab = []\n",
    "acc = []\n",
    "rec = []\n",
    "prec = []\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"Starting fold\", i)\n",
    "    q_start, q_end = q_fold_size[i], q_fold_size[i + 1]\n",
    "    nq_start, nq_end = nq_fold_size[i], nq_fold_size[i + 1]\n",
    "    test_data = queen_data[q_start:q_end] + non_queen_data[nq_start:nq_end]\n",
    "    test_labels = queen_labels[q_start:q_end] + non_queen_labels[nq_start:nq_end]\n",
    "    training_data = queen_data[:q_start] + queen_data[q_end:] + non_queen_data[:nq_start] + non_queen_data[nq_end:]\n",
    "    training_labels = queen_labels[:q_start] + queen_labels[q_end:] + non_queen_labels[:nq_start] + non_queen_labels[nq_end:]\n",
    "\n",
    "    uni_bi_vect = CountVectorizer(analyzer = \"word\",\n",
    "                                  ngram_range = (1,2),\n",
    "                                  token_pattern='(?u)\\\\b\\\\w+\\\\b')\n",
    "\n",
    "    # Train\n",
    "    X_train_counts = uni_bi_vect.fit_transform(training_data) # Learn the vocabulary dictionary and return term-document matrix.\n",
    "\n",
    "    # Get TF-IDF\n",
    "    tfidf_transformer = TfidfTransformer()\n",
    "    X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "    # Classifier\n",
    "    params = [{'kernel': ['rbf', 'linear'],\n",
    "              'gamma': [1e-4, 1e-3, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 100],\n",
    "              'C': [1, 5, 10, 50]}]\n",
    "    uni_bi_clf = GridSearchCV(svm.SVC(decision_function_shape='ovr'), params)\n",
    "    uni_bi_clf.fit(X_train_tfidf, training_labels)\n",
    "    print(\"Best parameters found:\")\n",
    "    print(uni_bi_clf.best_params_)\n",
    "\n",
    "    # Predict\n",
    "    X_new_counts = uni_bi_vect.transform(test_data)\n",
    "    X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "    all_pred.extend(uni_bi_clf.predict(X_new_tfidf))\n",
    "    all_true_lab.extend(test_labels)\n",
    "    \n",
    "    uni_bi_pred = uni_bi_clf.predict(X_new_tfidf)\n",
    "\n",
    "    acc.append(np.mean(uni_bi_pred == test_labels))\n",
    "    rec.append(metrics.recall_score(test_labels, uni_bi_pred, [\"queen\", \"not queen\"], average=\"macro\"))\n",
    "    prec.append(metrics.precision_score(test_labels, uni_bi_pred, [\"queen\", \"not queen\"], average=\"macro\"))\n",
    "\n",
    "print(\"Total Accuracy: \", sum([1 if all_pred[i] == all_true_lab[i] else 0 for i in range(len(all_pred))])/len(all_pred))\n",
    "print(\"Average Accuracy: \", sum(acc) / len(acc))\n",
    "print(\"Total Recall: \", str(metrics.recall_score(all_true_lab, all_pred, [\"queen\", \"not queen\"], average=\"macro\")))\n",
    "print(\"Average Recall: \", sum(rec) / len(rec))\n",
    "print(\"Total Precision: \", str(metrics.precision_score(all_true_lab, all_pred, [\"queen\", \"not queen\"], average=\"macro\")))\n",
    "print(\"Average Precision: \", sum(prec) / len(prec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      "{'C': 5, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Percentage Queens' Texts Predicted\n",
      "0.06838426750719474\n"
     ]
    }
   ],
   "source": [
    "uni_bi_vect = CountVectorizer(analyzer = \"word\",\n",
    "                                  ngram_range = (1,2),\n",
    "                                  token_pattern='(?u)\\\\b\\\\w+\\\\b')\n",
    "\n",
    "# Train\n",
    "X_train_counts = uni_bi_vect.fit_transform(all_data) # Learn the vocabulary dictionary and return term-document matrix.\n",
    "\n",
    "# Get TF-IDF\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "# Classifier\n",
    "params = [{'kernel': ['rbf', 'linear'],\n",
    "          'gamma': [1e-4, 1e-3, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 100],\n",
    "          'C': [1, 5, 10, 50]}]\n",
    "uni_bi_clf = GridSearchCV(svm.SVC(decision_function_shape='ovr'), params)\n",
    "uni_bi_clf.fit(X_train_tfidf, all_labels)\n",
    "print(\"Best parameters found:\")\n",
    "print(uni_bi_clf.best_params_)\n",
    "\n",
    "X_all_counts = uni_bi_vect.transform(data) \n",
    "X_all_tfidf = tfidf_transformer.transform(X_all_counts)\n",
    "uni_bi_pred_v2 = uni_bi_clf.predict(X_all_tfidf)\n",
    "print(\"Percentage Queens' Texts Predicted\")\n",
    "print(len([i for i in uni_bi_pred_v2 if i == 'queen'])/len(uni_bi_pred_v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13596"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queen_data = [x for x, y in zip(data, uni_bi_pred_v2) if y == \"queen\"]\n",
    "non_queens = [x for x, y in zip(data, uni_bi_pred_v2) if y == \"not queen\"]\n",
    "non_queen_labs = [x for x, y in zip(labs, uni_bi_pred_v2) if y == \"not queen\"]\n",
    "\n",
    "# set([x for x in non_queens if non_queens.count(x) > 1])\n",
    "len(non_queens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2871"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mult = [x for x in non_queen_labs if len(x) > 1]\n",
    "len(mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "560"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x for x, y in zip(non_queens, non_queen_labs) if len(y) > 1 and \"dead_animal\" not in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dead Animals archive size: 2470\n",
      "Domesticated Animals archive size: 8413\n",
      "Leather Objects archive size: 44\n",
      "Precious Objects archive size: 230\n",
      "Wild Animals archive size: 332\n",
      "Wool archive size: 14\n",
      "Unknown archive size: 2093\n"
     ]
    }
   ],
   "source": [
    "dead_animal_archive = []\n",
    "domesticated_animal_archive = []\n",
    "wild_animal_archive = []\n",
    "leather_object_archive = []\n",
    "precious_object_archive = []\n",
    "wool_archive = []\n",
    "Unknown_archive = []\n",
    "\n",
    "counter = 0\n",
    "for x, y in zip(non_queens, non_queen_labs):\n",
    "    lab = max(y, key = lambda x: len(y[x]))\n",
    "    if \"animal\" in lab and \"dead_animal\" in y.keys():\n",
    "        dead_animal_archive.append(x)\n",
    "    else:\n",
    "        exec(lab + \"_archive.append(x)\")\n",
    "    counter += 1\n",
    "      \n",
    "print(\"Dead Animals archive size:\", len(dead_animal_archive))\n",
    "print(\"Domesticated Animals archive size:\", len(domesticated_animal_archive))\n",
    "print(\"Leather Objects archive size:\", len(leather_object_archive))\n",
    "print(\"Precious Objects archive size:\", len(precious_object_archive))\n",
    "print(\"Wild Animals archive size:\", len(wild_animal_archive))\n",
    "print(\"Wool archive size:\", len(wool_archive))\n",
    "print(\"Unknown archive size:\", len(Unknown_archive))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above, we know that some lines correspond to multiple texts (with distinct PIDs). They should all be classified under the same archive; below, we'll match each PID with an archive. In addition, we'll do a check to make sure that duplicate texts are in the same archive according to the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14594"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_archive_map = {}\n",
    "extra_map = {}\n",
    "    \n",
    "for text in dead_animal_archive:\n",
    "    if text not in extra_map:\n",
    "        extra_map[text] = []\n",
    "        t_list = mapping[text]\n",
    "        for t in t_list:\n",
    "            extra_map[text].append([t.p_id, \"dead animal\"])\n",
    "            id_archive_map[t.p_id] = \"dead animal\"\n",
    "\n",
    "for text in wild_animal_archive:\n",
    "    if text not in extra_map:\n",
    "        extra_map[text] = []\n",
    "        t_list = mapping[text]\n",
    "        for t in t_list:\n",
    "            extra_map[text].append([t.p_id, \"wild animal\"])\n",
    "            id_archive_map[t.p_id] = \"wild animal\"\n",
    "    \n",
    "for text in domesticated_animal_archive:\n",
    "    if text not in extra_map:\n",
    "        extra_map[text] = []\n",
    "        t_list = mapping[text]\n",
    "        for t in t_list:\n",
    "            extra_map[text].append([t.p_id, \"domesticated animal\"])\n",
    "            id_archive_map[t.p_id] = \"domesticated animal\"\n",
    "        \n",
    "for text in leather_object_archive:\n",
    "    if text not in extra_map:\n",
    "        extra_map[text] = []\n",
    "        t_list = mapping[text]\n",
    "        for t in t_list:\n",
    "            extra_map[text].append([t.p_id, \"leather object\"])\n",
    "            id_archive_map[t.p_id] = \"leather object\"\n",
    "    \n",
    "for text in precious_object_archive:\n",
    "    if text not in extra_map:\n",
    "        extra_map[text] = []\n",
    "        t_list = mapping[text]\n",
    "        for t in t_list:\n",
    "            extra_map[text].append([t.p_id, \"precious object\"])\n",
    "            id_archive_map[t.p_id] = \"precious object\"\n",
    "\n",
    "for text in wool_archive:\n",
    "    if text not in extra_map:\n",
    "        extra_map[text] = []\n",
    "        t_list = mapping[text]\n",
    "        for t in t_list:\n",
    "            extra_map[text].append([t.p_id, \"wool\"])\n",
    "            id_archive_map[t.p_id] = \"wool\"\n",
    "    \n",
    "for text in Unknown_archive:\n",
    "    if text not in extra_map:\n",
    "        extra_map[text] = []\n",
    "        t_list = mapping[text]\n",
    "        for t in t_list:\n",
    "            extra_map[text].append([t.p_id, \"unknown\"])\n",
    "            id_archive_map[t.p_id] = \"unknown\"\n",
    "\n",
    "for text in queen_data:\n",
    "    if text not in extra_map:\n",
    "        extra_map[text] = []\n",
    "        t_list = mapping[text]\n",
    "        for t in t_list:\n",
    "            extra_map[text].append([t.p_id, \"queen\"])\n",
    "            id_archive_map[t.p_id] = \"queen\"\n",
    "            \n",
    "len(id_archive_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicated_texts = [p for p in extra_map.items() if len(p[1]) > 1]\n",
    "\n",
    "dup_archive_map = {}\n",
    "\n",
    "for pair in duplicated_texts:\n",
    "    archives = [t[1] for t in pair[1]]\n",
    "    dup_archive_map[pair[0]] = set(archives)\n",
    "    \n",
    "conflicts = [p for p in dup_map.items() if len(p[1]) > 1]\n",
    "len(conflicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above results, we can see that all duplicated texts are classified as belonging to the same archive. There shouldn't be any issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive = open('archive_map.csv', 'w')\n",
    "archive.write(\"PID,Archive\\n\")\n",
    "for k, v in id_archive_map.items():\n",
    "    archive.write(k + \",\" + v + \"\\n\")\n",
    "archive.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
